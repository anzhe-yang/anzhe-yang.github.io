[{"title":"Machine Learning (Coursera)","url":"/2019/07/08/Machine-Learning-Coursera/","content":"\n\n### 写在前面\n\n本文是在自己的理解上总结了Coursera网站上吴恩达机器学习的课程内容，目录章节与课程有所出入。\n\n### 线性回归\n\n首先提出一个问题，如何用线性函数去预测房价。\n\n解决这个问题的思路是可以采用简单的一维函数$ y=kx+b $去拟合训练数据，通过一个学习算法去学习最优的参数，使得通过这个函数所得到的结果与预想的结果相差无几，之后使用这个函数去预测新的值，即\n\n$$ h_\\theta(x)=\\theta_0+\\theta_1x $$\n\n那么如何去得到最优的参数呢？可以使用一个代价函数去评价当前参数是否是最优的，即\n\n$$ J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 $$\n\n式中：$m$是训练数据的数量。\n\n最终的目标就是使得这个代价函数越小，这时得到的参数就是最优的。\n\n为了学习到更好的参数，从而使得代价函数最小，这里可以使用梯度下降法使得每次迭代后通过改变参数取值，使得代价函数下降，即\n\n$$ \\theta_j=\\theta_j-\\alpha\\cdot \\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1) $$\n\n梯度优化的过程：\n\n1. 从设定的初始值开始\n2. 不断的改变每个参数，使得代价函数的值有所降低\n3. 直到得到最低的代价函数值，从而得到最优的参数\n\n在迭代优化的过程中，需要计算完所有参数的优化值之后，再更新参数。否则如果每次计算完一个参数的梯度值就将更新参数的话，那么下一次计算代价函数的时候所得的值会跟之前不一样，导致不同步的参数更新。如下图\n\n<center>{% asset_img 1-1.png 500 200 迭代优化 %}</center>\n\n当梯度是正值时，说明函数曲线相对于最优点在上升，所以参数需要减去其值，向最优点靠近。\n\n当梯度是负值时，说明函数曲线相对于最优点在下降，所以参数需要增加其值，向最优点靠近。\n\n<center>{% asset_img 1-2.png 500 300 梯度下降 %}</center>\n\n从图中可以看出，当学习率$ \\alpha $特别小时，优化速度非常慢；当学习率$\\alpha$特别大时，优化速度很快，但可能越过最优点，导致不收敛。\n\n当每个特征值的范围相差过大时，可能会导致优化过程抖动不平缓，使得优化过程过慢。这时需要将每个特征归一化到同一尺度范围下，也就是特征缩放，将每个特征缩放到-1和1之间。即\n\n$$ x_i^{(j)}=\\frac{x_i^{j}-\\bar{x_i}}{S_i} $$\n\n式中：$ S_i $可以为标准差，也可以为$\\max(x_i)-\\min(x_i)$。\n\n**如何选取学习率**\n\n在梯度优化的过程中，可以随着迭代次数的增加，适当降低学习率。因为当损失快要达到最优点时，需要减少步长来达到此最优点。\n\n如果每次迭代之后，损失值的降低程度小于$10^{-3}$，那么可以认为当前函数已经收敛，可以停止训练。\n\n一个有效的学习率可以使得代价函数每次迭代后，损失都可以下降一些。\n\n但如果学习率特别小的话，梯度下降的速度会变得非常慢。\n\n<center>{% asset_img 1-3.png 500 200 学习率影响 %}</center>\n当发生以上三种情况时，说明当前学习率过大，导致不收敛的情况，需要选择一个更小的学习率来完成迭代。\n\n一个建议的学习率选择过程为：\n\n> …, 0.001, 0.003, 0.01, 0.03,  0.1, 0.3, 1, ...\n\n前面提到的线性回归目标函数中，仅使用了一次项，当使用多项式回归去拟合函数时，即$h_\\theta(x)=\\theta_0+\\theta_1x+\\theta_2x^2+\\theta_3x^3+\\cdots$，当使用多项式回归方法时，数据的标准化工作就显得尤为重要。\n\n这时，就可以使用常规等式法去求解最优的参数，使得损失函数为零。\n\n$$ \\frac{\\partial}{\\partial\\theta_j}J(\\theta)=0\\ \\ \\ \\ \\ \\ \\ \\ -> \\theta=(x^Tx)^{-1}x^Ty $$\n\n以下是这两种方法的区别和优缺点：\n\n| Gradient descent                 | Normal equation                            |\n| -------------------------------- | ------------------------------------------ |\n| 需要选择学习率                   | 不需要选择学习率                           |\n| 迭代次数多                       | 没有迭代的过程                             |\n| 特征数量较多时也能达到很好的效果 | 由于存在逆运算，特征数量较多时计算速度太慢 |\n\n> 当特征矩阵不可逆时，说明有冗余的特征，需要对特征进行处理或使用正则化。\n\n### 逻辑回归\n\n逻辑回归是回归问题的离散化，目的是解决分类问题。\n\n分类任务需要确切的结果值，如0代表不是，1代表是。逻辑回归的结果$ 0\\le h_\\theta(x)\\le1 $，这就需要一个边界去判别在什么范围内结果为0，什么范围内结果为1。这就引出了激活函数：\n\n$$ h_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}} $$\n\n这个激活函数是sigmoid函数，它能有效将函数值分在两个区间内。\n\n之后就是确定一个决策边界：\n\n当$h_\\theta(x)\\ge0.5,\\theta^Tx\\ge0$时，$y=1$\n\n当$h_\\theta(x)\\le0.5,\\theta^Tx\\le0$时，$y=0$\n\n如何去选择参数来将结果接近于真实值？这时需要一个目标函数：\n\n$$ J(\\theta)=\\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})^2 $$\n\n如果采用上述线性回归代价函数的话，由于非线性激活函数的引入，结果会产生\"非凸形\"，如下图\n\n<center>{% asset_img 2-1.png 500 300 非凸形 %}</center>\n\n这时就需要另一种代价函数，因为结果值无非是0和1，所以针对这两种情况可以建立一个代价函数。\n\n$$ Cost(h_\\theta(x),y)=\\begin{cases}-\\log{(h_\\theta(x))}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ if\\ y=1 \\\\ -\\log{(1-h_\\theta(x))}\\ \\ \\ if\\ y=0 \\end{cases} $$\n\n当预测结果和真实结果一致时，我们希望损失为零；当不一致时，我们希望损失变得很大。\n\n因为$y$仅可能为1或者0，所以可以将上式变为：\n\n$$ J(\\theta)=-y\\log{(h_\\theta(x))}-(1-y)\\log{(1-h_\\theta(x))} $$\n\n使用梯度下降法去降低损失函数，从而优化参数。\n\n$$ \\theta=\\theta-\\alpha\\frac{\\partial}{\\partial\\theta}J(\\theta) $$\n\n通过上述优化方法可能会产生两个不好的结果，一个是过拟合，造成低偏差、高方差的现象，一个是欠拟合，造成高偏差、低方差的现象。\n\n<center>{% asset_img 2-2.png 500 220 偏差、方差现象 %}</center>\n\n解决过拟合有以下几种方法：\n\n1. 降低特征的数量（可以手动或者通过算法选择一些特征，抛弃一些特征）\n2. 正则化（保留所有特征，但降低每个特征对结果的影响程度）\n\n正则化就是在损失函数的最后加入一些惩罚项，比如加入$100\\times\\theta_3$，这时如果$\\theta_3$变的大就会严重增大损失函数的值，通过优化手段就可以让函数自己去减少此参数的值，从而降低此参数的影响力，完成优化的效果。\n\n$$ J(\\theta)=\\frac{1}{2m}[\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda\\sum^n_{j=1}\\theta^2_j] $$\n\n这里正则项是不包含$\\theta_0$参数的，可以把它理解成一个偏置。\n\n- 如果$\\lambda$过大，会造成抑制参数的效果变得很强，产生欠拟合的效应。\n\n- 如果$\\lambda$过小，会造成抑制参数的效果变得很弱，产生过拟合的效应。\n\n那么，之后的梯度下降过程就变成了：\n\n$$ \\theta_0=\\theta_0-\\alpha\\frac{1}{m}(\\frac{\\partial}{\\partial\\theta_0}J(\\theta))=\\theta_0-\\alpha\\frac{1}{m}(\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x_0^{(i)}) $$\n\n$$ \\theta_j=\\theta_j-\\alpha[\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}-\\frac{\\lambda}{m}\\theta_j]=\\theta_j(1-\\alpha\\frac{\\lambda}{m})-\\alpha\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} $$\n\n由于$ 1-\\alpha\\frac{\\lambda}{m}<1 $，所以梯度下降的过程中参数会一直减小。\n\n### 神经网络\n\n<center>{% asset_img 3-1.png 500 300 神经网络 %}</center>\n\n上图是一个简单神经网络的实例，图中有输入单元、隐藏单元和输出单元，而网络的输出即为：\n\n$$ h_\\theta(x)=a_1^{(3)}=g(\\theta_{10}^{(2)}\\cdot a_0^{2}+\\theta_{11}^{(2)}\\cdot a_1^{(2)}+\\theta_{12}^{(2)}\\cdot a_2^{(2)}+\\theta_{13}^{(2)}\\cdot a_3^{(2)}) $$\n\n如果网络中的第$j$层有$s_j$个单元，第$j+1$层有$s_{j+1}$个单元，那么第$j$层的参数$\\theta_j$就会有$s_{j+1}\\times(s_j+1)$个单元。\n\n神经网络可以完成一种非线性的计算——异或：\n\n<center>{% asset_img 3-2.png 500 300 异或运算 %}</center>\n\n神经网络可以完成多类别的表达：\n\n$$ y^{(i)}:\\begin{bmatrix}1 \\\\0 \\\\. \\\\. \\\\. \\\\0 \\end{bmatrix}\\begin{bmatrix}0 \\\\1 \\\\. \\\\. \\\\. \\\\0 \\end{bmatrix} … \\begin{bmatrix}0 \\\\0 \\\\. \\\\. \\\\. \\\\1 \\end{bmatrix}$$\n\n上式中第一个矢量代表第一类，第二个矢量代表第二类，以此类推，最后一个矢量代表最后一类，类别的个数和矢量中元素的个数一致。\n\n神经网络的代价函数如下：\n\n$$ J(\\theta)=-\\frac{1}{m}[\\sum^m_{i=1}\\sum^K_{k=1}y_k^{(i)}\\log{(h_\\theta(x_k^{(i)}))}+(1-y_k^{(i)})\\log{(1-h_\\theta(x_k^{(i)}))}]+\\frac{\\lambda}{2m}\\sum^{L-1}_{l=1}\\sum^{s_l}_{i=1}\\sum^{s_{l+1}}_{j=1}(\\theta_{ji}^{(l)})^2  $$\n\n式中：$ (h_\\theta(x))_i $表示第$i$层的输出，$m$表示特征的个数，$L$表示神经网络的层数，输出代表第1层，$s_l$表示第$l$层不包含偏置之后的单元数。\n\n那么，接下来输出结果的大概计算过程如下：\n\n<center>{% asset_img 3-3.png 500 300 计算输出 %}</center>\n\n假设$\\delta_j^{(l)}$表示第$l$层第$j$个单元的损失，那么首先最后一层中某个单元的损失为\n\n$$ \\delta^{(4)}=a^{(4)}-y $$\n\n因为输出结果与最后一层之间没有激活函数，那么接下来每一层的传播如下\n\n$$ \\delta^{(3)}=(\\theta^{(3)})^T\\delta^{(4)}.*g'(z^{(3)}) $$\n\n具体过程如下\n\n<center>{% asset_img 3-4.png 500 300 反向传播 %}</center>\n\n在梯度优化的过程中可能由于编程错误而导致一些不好的结果，可能导致最终函数无法收敛。如果在训练的过程中能够检查梯度下降是否正确，可以在训练的时候避免这些错误。\n\n<center>{% asset_img 3-5.png 500 180 梯度检查 %}</center>\n\n$$ \\frac{\\partial}{\\partial\\theta_i}J(\\theta)\\approx\\frac{J(\\theta+\\epsilon)-J(\\theta-\\epsilon)}{2\\epsilon} $$\n\n所以在求解多个参数最优解的过程中，可以分别对每个参数进行梯度检查工作，检查某个参数的梯度下降过程是否正确，确保反向传播的结果和梯度检查的结果一致。不过此项工作仅在训练过程中使用，测试过程需要去掉这一部分。\n\n**参数初始化**\n\n如果将参数初始化为零向量，则会导致$ a_1^{(2)}=a_2^{(2)} $，那么$ \\delta_1^{(2)}=\\delta_2^{(2)} $，所以会造成没有更新参数的结果，传回的梯度会零。\n\n所以参数初始化有一个原则，就是切忌将参数初始化成对称的结构。\n\n**小结**\n\n训练神经网络的主要过程如下：\n\n1. 随机初始化参数权重\n2. 计算前向传播并得到结果\n3. 将结果带入代价函数计算其损失值\n4. 通过对损失值求导来反向传播参数的损失\n5. 使用梯度检查方法检查反向传播的结果和梯度估计的结果是否一致\n6. 利用梯度下降和优化方法对反向传播进行操作，从而通过调整参数来最小化代价函数\n\n### 应用机器学习过程中的一些建议\n\n当你应用正则化线性回归到实际任务中时，如果在预测时产生了很大的错误，可以尝试以下措施：\n\n- 增加训练数据——处理高方差问题\n- 降低特征冗余——处理高方差问题\n- 增加额外的特征——处理高偏差问题\n- 加入一下多项式特征——处理高偏差问题\n- 增加正则化系数的值——处理高方差问题\n- 减小正则化系数的值——处理高偏差问题\n\n**数据集设置建议**\n\n将数据集分为三个部分：训练集、评估集、测试集，并通过交叉验证去得到最好的参数。\n\n<center>{% asset_img 4-1.png 300 300 正则化参数的影响 %}</center>\n上图是正则化参数与模型好坏的比较趋势，当参数特别小时，训练集错误率很低，但评估集错误率就很高。随着参数的增加，训练集错误率会提升，而评估集错误率会先下降再上升。因为当偏差高到一定程度时，模型效果就会非常差，几乎完成不了任何任务。所以一个恰到好处的正则化参数会平衡训练集误差和评估集误差，最终得到一个较好的模型。\n\n<center>{% asset_img 4-2.png 300 180 训练集大小的影响 %}</center>\n\n上图是训练集大小和模型好坏的比较趋势，随着训练集的增加，模型的偏差会慢慢增加，而方差会慢慢减小，最终两个误差会趋于平和，达到较好的效果。\n\n**神经网络复杂度问题**\n\n当训练一个小型神经网络的时候，参数会比较少，计算效率比较高，但可能会有欠拟合的问题。\n\n当训练一个大型神经网络的时候，参数会比较多，计算效率比较低，而且会有过拟合的问题，可以采用正则化去降低过拟合的影响。\n\n**误差分析**\n\n评估一个模型的好坏时可以采用准确率和召回率指标。\n\n<center>{% asset_img 4-3.png 300 250 评价指标 %}</center>\n\n准确率表示所有模型预测结果为1时，预测正确的比例，即\n\n$$ Precision=\\frac{True\\ positive}{Predicted\\ positive}=\\frac{True\\ positive}{True\\ positive+False\\ positive} $$\n\n召回率表示所有实际结果为1时，预测正确的比例，即\n\n$$ Recall=\\frac{True\\ positive}{Actual\\ positive}=\\frac{True\\ positive}{True\\ positive+False\\ negative} $$\n\n如何去综合上述两个评估指标？\n\n$$ F_1\\ Score=2\\cdot\\frac{P\\cdot R}{P+R} $$\n\n如何设计一个具有高准确率的学习系统？\n\n> It's not who has the best algorithm that wins. It's who has the most data.\n\n### 支持向量机\n\n<center>{% asset_img 5-1.png 500 200 代价函数 %}</center>\n通过对逻辑回归中代价函数的分析可知，当标签为正样本时，代价函数如上左图所示，当标签为负样本时，代价函数如上右图所示。\n\n为了让损失值降到最低，当样本是正样本时，我们希望通过激活函数之后的$g(x)$即$sigmoid(\\theta^Tx)\\ge0$。从上图可以看出，为了满足条件，$z$的值可以大于0，只要近似大于1就可以满足，那么这里就存在一个边界区间的问题。\n\n<center>{% asset_img 5-2.png 500 150 边界 %}</center>\n\n逻辑回归代价函数的形式为：$ A+\\lambda B $，我们更加关注第二项$B$\n\nSVM代价函数的形式为：$C\\cdot A+B$，我们更加关注第一项$A$，即\n\n$$ \\min\\limits_\\theta C\\sum^m_{i=1}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum^n_{i=1}\\theta^2_j $$\n\n<center>{% asset_img 5-3.png 500 400 解决边界问题 %}</center>\n\n支持向量机为了解决上述一个边界区间的问题，将代价函数进行了修改。从上图可以看出，当$z$小于等于1时，$cost$函数严格大于0。所以SVM与逻辑回归最大的区别就在于\n\n$$ \\begin{cases}y=1\\ \\ \\ \\theta^Tx\\ge1\\ \\ \\ not\\ \\ge0\\\\ y=0\\ \\ \\ \\theta^Tx\\le1\\ \\ \\ not\\ \\le0\\end{cases} $$\n\n当$C$很大时，希望$A$这部分函数值趋于0，也就是可以让$cost$函数这部分趋于0，从而控制参数$\\theta$的选取。下图可以看出$C$的选取对于边界的影响。\n\n<center>{% asset_img 5-4.png 500 280 参数影响 %}</center>\n\n**最大边界理论**\n\n<center>{% asset_img 5-5.png 300 280 最大边界 %}</center>\n\nSVM的决策边界为$\\min\\limits_\\theta\\frac{1}{2}\\sum^n_{j=1}\\theta^2_j=\\frac{1}{2}||\\theta||^2$，约束条件为$ \\begin{cases}\\theta^Tx\\ge0\\ \\ \\ \\ if\\ y=1\\\\ \\theta^Tx\\le-1\\ if\\ y=0\\end{cases} $\n\n$$ \\theta^Tx^{(i)}=p^{(i)}\\cdot ||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)} $$\n\n式中：$p^{(i)}$是$x$在$\\theta$上的投影。\n\n若想$||\\theta||$的值越小，就应该使得$p^{(i)}$的值越大，当向量$\\theta$的长度等于$p$时，也就得到了最大间隔，即最大边界。\n\n<center>{% asset_img 5-6.png 500 180 最大边界 %}</center>\n\n以上仅可以解决线性可分的情况，当遇到线性不可分的情况，就需要加入核函数。\n\n**核函数**\n\n<center>{% asset_img 1-3.png 500 250 非线性情况 %}</center>\n\n举个例子讲解一下什么是核函数：\n\n例如当进行kNN分类时，输入一个数据x，必须计算它与每个聚类中心数据点的相似度来决定它被分到哪一类别中，而这个计算相似度的函数就是核函数。\n\n其中聚类中心也称landmarks。\n\n当加入核函数$f(x)$之后，预测值为正样本的情况为$\\theta^Tf\\ge0(\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_mf_m)$，SVM的代价函数可以写为\n\n$$ \\min\\limits_\\theta C\\sum^m_{i=1}[y^{(i)}cost_1(\\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\\theta^Tf^{(i)})]+\\frac{1}{2}\\sum^m_{i=1}\\theta^2_j $$\n\n式中：$C=\\frac{1}{\\lambda}$，越大导致高偏差，越小导致高方差。\n\n**SVM与逻辑回归的区别**\n\n- 当特征数远远大于训练样本数时，选择逻辑回归或者不加核函数的SVM方法\n- 当特征数远远小于训练样本数时，需要增加一些特征，并选择逻辑回归或者不加核函数的SVM方法\n- 当特征数非常少，训练样本数适当时，选择加核函数的SVM方法\n\n### 非监督学习\n\n非监督学习是一个聚类算法，事前并不需要知道数据的标签，只是根据数据的特征和分布进行类别聚类。\n\n**K-means**\n\n输入：聚类中心个数k和训练数据\n\n步骤：\n\n```\n随机初始化聚类中心\nRepeat{\n\tfor i = 1 ~ m\n\t\tc(i) = 距离最近的聚类中心 min||x-u||\n\tfor k = 1 ~ K\n\t\t更新聚类中心，取平均值\n}\n```\n\n此算法需要优化的目标函数为\n\n$$ J(c^{(i)},…,c^{(m)},\\mu_1,…,\\mu_K)=\\frac{1}{m}\\sum^m_{i=1}||x^{(i)}-\\mu_{c^{(i)}}||^2 $$\n\n式中：$c^{(i)}$为当前数据$x^{(i)}$当前所从属的聚类中心，$\\mu_k$表示聚类中心，$\\mu_{c^{(i)}}$表示当前数据$x^{(i)}$所属类别的聚类中心点。\n\n<center>{% asset_img 6-1.png 400 300 参数K的取值 %}</center>\n\n在选取k值方面，可以选取多个k值，并分别计算代价函数的结果值，如上图。图中有一个肘点，即k=3的情况，可以认为是最优的选择。\n\n**PCA**\n\n<center>{% asset_img 6-2.png 400 400 二维降一维 %}</center>\n<center>{% asset_img 6-3.png 500 200 三维降二维 %}</center>\n\n上图是一些数据降维的实例，从2维到1维，从3维到2维。每次降维的过程都会寻找一个基本线或者基本面，大部分数据都从属于这个基本空间上。\n\n<center>{% asset_img 6-4.png 500 400 降维过程 %}</center>\nPCA算法就是寻找一个投影平面，使得投影误差降到最小。投影误差就是每个数据点到投影线上的距离。图中红线和粉线都可以被视为一个投影线，而红线的投影误差小于粉线的投影误差。\n\n算法过程如下：\n\n1. 将输入数据做尺度缩放和均值归一化，之后用$x_i-\\mu_i$来代替数据$x_i$\n2. 计算协方差矩阵$\\sum=\\frac{1}{m}\\times X'\\times X$\n3. 计算协方差矩阵的特征向量和特征值\n4. 取前k个特征值对应的特征向量，并将其组合成新的矩阵$Z^{(i)}$\n5. 之后将此矩阵与输入数据相乘，得到降维后的数据$U_{reduce}$\n\n数据恢复的过程为$ x^{(i)}_{approx}=U_{reduce}\\cdot Z^{(i)} $\n\n如何选取k值？\n\n$$ \\frac{\\frac{1}{m}\\sum^m_{i=1}||x^{(i)}-x^{(i)}_{apporx}||^2}{\\frac{1}{m}\\sum^m_{i=1}||x^{(i)}||^2}\\le0.01 $$\n\n如果上式选取0.01，则说明99%的方差被保留，如果选取0.05，说明95%的方差信息被保留。\n\n使用PCA算法去避免过拟合影响的做法是不可取的，最好是使用正则化。\n\n部署一个机器学习应用时，首先尝试使用原始数据去做，如果达不到效果，再尝试使用PCA方法。\n\n### 异常检测\n\n在工程实践中，同一类别的数据大部分是分布在一起的，但有少量样本虽然属于同一类别，样本分布却离大部分距离较远，这类样本属于异常样本。\n\n算法在训练的过程中可以通过松弛系数来对异常样本进行处理，但总之异常样本对算法的优化起着副作用的。如何检测出异常样本并忽略它，实际中通常采用正态分布去检测它。\n\n$$ P(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^-{\\frac{(x-\\mu)^2}{2\\sigma^2}} $$\n\n当取不同的$\\mu$和$\\sigma$值时，高斯分布曲线是不一样的。前者影响曲线的中心点，后者影响曲线的面积大小。\n\n**检测算法**\n\n1. 选出你认为可能是异常的特征\n2. 拟合参数$\\mu$和$\\sigma$\n3. 测试新的样本数据，计算$p(x)$\n\n$$ p(x)=\\prod^n_{j=1}{p(x_j;\\mu_j,\\sigma^2_j)} $$\n\n当$p(x)<\\varepsilon$时，即小于某个阈值时，该特征为异常值。\n\n**评估算法**\n\n1. 计算出适合训练集的参数\n2. 在评估集或者测试集上进行预测，如果$p(x)<\\varepsilon$，则为1，否则为0\n3. 计算PR指数或者F1值\n\n**异常检测算法和监督学习的选择**\n\n选择异常检测算法：\n\n1. 正样本很少而负样本很多时\n2. 数据集有很多不同类型的异常样本，而且未来的异常类型可能还与现存的不同\n3. 从正样本中学习异常样本很难\n\n监督学习：\n\n1. 拥有大量的正负样本时\n2. 测试集与训练集相似\n\n**选择特征**\n\n可以对特征进行一些变换，如取$\\log$对数，或者取平方根，开方跟等等\n\n**对异常检测的误差分析**\n\n我们希望正常样本的$p(x)$值很大，而异常样本很小。而实际情况两者看不出很大的差别，这时我们可以增加一些特征，将特征维数增高。\n\n### 推荐系统\n\n目标函数：\n\n$$ \\min\\limits_{\\theta^{(j)}}\\frac{1}{2}\\sum_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum^n_{k=1}(\\theta_k^{(j)})^2 $$\n\n这里需要学习多个参数$\\theta^{(i)},\\theta^{(2)}…$，所以每次梯度下降时需要对每个参数都进行优化。\n\n**协同滤波算法**\n\n假设一个参数$\\theta$，从而估计$x$，之后通过此$x$估计参数$\\theta$，以此类推。\n\n### 大规模机器学习\n\n数据集比较大的时候，可以采用随机梯度下降或者小批量梯度下降。\n\n随机梯度下降：\n\n1. 随机打乱顺序\n2. 每次只关注一个训练样本进行参数更新\n\n小批量梯度下降：\n\n1. 每次关注少量样本进行参数更新\n\n在训练的过程中可以检查梯度是否收敛：\n\n1. 取最后1000组样本，求目标函数的平均值，画图\n2. 若直线抖动幅度较大，增加样本量，再求平均\n3. 若直线在上升，则减小学习率\n4. 若在最小点周围，可采用变化的学习率\n\n<center>{% asset_img 7-1.png 500 300 损失减小过程 %}</center>\n\n**在线学习**\n\n输入一对样本，更新一次参数，在线更新网络。\n\n### 应用实例：OCR\n\nPipeline：\n\n1. 寻找图片上的文字\n2. 文字分割\n3. 文字分类\n\n### 总结\n\n**监督学习**\n\n线性回归、逻辑回归、神经网络、SVM\n\n**非监督学习**\n\nK-means、PCA、异常检测\n\n**特殊应用**\n\n推荐系统、大规模机器学习\n\n**建立机器学习系统的建议**\n\n方差/偏差、正则化、评估算法、学习曲线、错误分析等","tags":["Method Summary"]},{"title":"问题总结","url":"/2019/05/17/实习面试总结/","content":"\n2. 了解过哪些损失函数。\n\n   - 对数损失函数：$\\mathcal{L}=-y(\\log{f(x)})-(1-y)(1-\\log{f(x)})$\n\n   - 平方损失函数：$\\mathcal{L}=(y-f(x))^2$\n\n   - 指数损失函数：$\\mathcal{L}=\\exp{(-yf(x))}$\n\n   - Hinge损失函数：$\\mathcal{L}=max(0,1-yf(x))$\n\n   - 绝对值损失函数：$\\mathcal{L}=|y-f(x)|$\n\n3. 从一组数组中找出和最大的最长连续子串。\n\n   \n\n   **解决思路：**利用动态规划方法，每次找出以第`i`个元素为末尾组成的子串的最大和。如果前一最大和小于等于零，则当前`dp`等于当前元素值；如果大于零，则当前`dp`等于当前值加上前一最大和。每次循环都判断一次前`i`个元素中子串的最大和，即`maxSum`。\n   \n   ```java\n       public int largestSubarray(int[] nums) {\n           /**\n            * @Description: Find the largest continuous subarray in the array.\n            * @Params: [nums] Array.\n            * @Return: int The largest sum.\n            * @Date: 2019-03-26\n            */\n           if(nums.length == 0) {\n               return 0;\n           }\n   \n           int maxSum = 0;\n           int[] dp = new int[nums.length];\n           for(int i = 0; i < nums.length; i++) {\n               if(i == 0 || dp[i-1] <= 0) {\n                   dp[i] = nums[i];\n               }\n               else {\n                   dp[i] = dp[i-1] + nums[i];\n               }\n               maxSum = max(dp[i], maxSum);\n           }\n           return maxSum;\n       }\n   ```\n\n\n\n2. 写一下逻辑回归的损失函数。\n\n   $$J(\\theta)=-\\frac{1}{m}[\\sum^m_{i=1}(y^{(i)}\\log{h_\\theta(x^{(i)})+(1-y^{(i)})\\log{(1-h_\\theta(x^{(i)})})})]$$\n\n3. PCA用代码实现。\n\n   \n\n   a. 将数据中心化，即使其均值为零\n\n   b. 计算数据的协方差矩阵\n\n   c. 计算协方差矩阵的特征值和特征向量\n\n   d. 将特征值进行排序，取前`k`个特征值，并将其对应的特征向量组合起来形成矩阵`P`\n\n   e. 将矩阵`P`与原数据矩阵相乘，得到降维后的数据\n\n4. K-Means用代码实现。\n\n   \n\n   a. 从数据中随机选择`k`个值作为初始均值点\n\n   b. 计算其它数据与均值点的**距离**，将其分配到离它最近的均值点区域，成为某一类别，每个数据点只能被分配到一个聚类中心上\n\n   c. 重新计算每一类别的均值点，作为新的聚类中心点\n\n   d. 重复以上两步，直到迭代结束\n\n\n\n2. 了解过哪些梯度下降的优化方法？有什么区别？\n\n   - **Batch Gradient Descent**（批梯度下降）\n\n   $$ \\theta=\\theta-\\eta\\cdot\\nabla_\\theta J(\\theta) $$\n\n   此方法对所有样本计算梯度后求平均，并更新参数。由于每次执行更新操作时，都需要在整个数据集上计算所有梯度，会导致速度较慢，且容易造成内存溢出。对于凸误差函数，此方法能够保证收敛到全局最小值；而对于非凸函数，就可能会收敛到一个局部最小值。\n\n   - **SGD**（随机梯度下降）\n\n   $$ \\theta=\\theta-\\eta\\cdot\\nabla_\\theta J(\\theta;x^{(i)};y^{(i)}) $$\n\n   此方法每次计算一个样本的梯度后就更新参数，运行速度较快，可用于在线学习。由于高频率的更新操作，导致目标函数容易出现剧烈波动。当学习率较小时，可以达到与批梯度下降一样的结果。\n\n   - **Mini-Batch GD**（小批量梯度下降）\n\n   此方法结合了上述两种方法的优点，在更新时使用较小批量训练样本的平均梯度，可以减小参数更新的方法，提升收敛的稳定性。\n\n   - **Momentum**（动量）\n\n   上述梯度下降方法存在着某些问题，如在梯度平缓时下降非常慢，在梯度陡峭时容易抖动；容易陷入局部极小值或者马鞍点；对学习率的设置较为敏感；整体过程若采用一个学习率性能会下降，因为如果特征是稀疏且频率差异很大时，相同的学习率对于不同稀疏或频率的特征学习差异很大，造成不好的效果。\n\n   $$ v_t=\\gamma v_{t-1}+\\eta\\nabla_\\theta J(\\theta) $$\n\n   $$ \\theta = \\theta-v_t $$\n\n   为了解决上述问题，提出了动量法。此方法在每次梯度下降时都加上之前运动方向上的动量，在梯度平缓时下降更快，在梯度陡峭时减少抖动。同时，在某个点处梯度方向与运动方向一致，则动量参数增大，若不一致，则动量参数减小。这样就可以得到更快的收敛速度，并可以减少抖动影响。\n\n   - **Nesterov**（梯度加速法）\n\n   $$ v_t=\\gamma v_{t-1}+\\eta\\nabla_\\theta J(\\theta-\\gamma v_{t-1}) $$\n\n   $$ \\theta=\\theta-v_t $$\n\n   若根据动量进行大步的跳跃，会使得梯度盲目的进行下降，缺少一个合理的限制。此方法能够根据之前的动量进行跳跃，然后计算梯度进行校正，从而实现参数更新，防止大幅震荡，错过最优点。此方法使参数更新与误差函数的斜率相适应，并根据每个参数的重要性来调整和更新参数。\n\n   - **Adagrad**\n\n   此方法是通过参数来调整合适的学习率，使得下降的过程对特征的稀疏性不敏感，非常适合树立稀疏的特征。\n\n   $$ \\theta=\\theta-\\frac{\\eta}{\\sqrt{grad_{save}+\\epsilon}}J(\\theta) $$\n\n   ```python\n   grad_save = 0\n   while True:\n     dx = compute_gradient(x)\n     grad_save += dx * dx\n     x -= lr / (np.sqrt(grad_save)+1e-7) * dx\n   ```\n\n   此方法将每一维度的梯度平方都保存下来，并在更新参数的时候，将学习率除以这个参数，使每一维度的学习率不一样，在梯度大时减小下降速度，梯度小时加快下降速度，无需手动调整学习率。\n\n   - **Adadelta**\n\n   此方法是上一个方法的扩展版本，主要处理学习速率只能单调递减的问题。此方法不是积累所有之前的梯度平方，而是将累积之前梯度的窗口限制到某个固定大小。\n\n   $$ E_g^2=\\gamma E_g^2+(1-\\gamma)J(\\theta)^2 $$\n\n   $$ \\theta=\\theta-\\frac{\\eta}{\\sqrt{E_g^2+\\epsilon}} J(\\theta) $$\n\n   - **RMSprop**\n\n   此方法是对上一个方法的改进，主要增加了一个延迟因子平衡梯度平方和上一个参数。\n\n   $$ \\theta=\\theta-\\frac{\\eta}{\\sqrt{decay\\cdot grad_{save}+(1-decay)J(\\theta)^2}}J(\\theta) $$\n\n   ```python\n   grad_save = 0\n   while True:\n     dx = compute_gradient(x)\n     grad_save = decay * grad_save + (1-decay) * dx * dx\n     x -= lr / (np.sqrt(grad_save)+1e-7) * dx\n   ```\n\n   - **Adam**\n\n   此方法结合了动量法和RMSprop的特征，增加了自适应学习率。\n\n3. 写一下Adam的优化公式。\n\n     ```python\n   first_moment = 0\n   second_moment = 0\n   while True:\n     # beta1=0.9 beta2=0.999\n     dx = compute_gradient(x)\n     # Momentum\n     first_moment = beta1 * first_moment + (1-beta1) * dx\n     # RMSProp\n     second_moment = beta2 * second_moment + (1-beta2) * dx * dx\n     # Bias correction\n     first_unbias = first_moment / (1-beta1**2)\n     second_unbias = second_moment / (1-beta2**2)\n     # RMSProp\n     x -= lr * first_unbias / (np.sqrt(second_unbias)+1e-7)\n   ```\n\n4. 写一下逻辑回归的损失函数。\n\n     $$ Loss=y_{label}\\log{y}+(1-y_{label})\\log{(1-y)} $$\n\n   $$ J(\\theta)=\\frac{1}{2m}\\sum^m_{i=1}(y^{(i)}-y_{label}^{(i)})^2 $$\n\n5. 如何理解卷积和池化这两个过程？\n\n  **卷积：**一维信号的卷积：$ y[n]=x[n]*h[n]=\\sum_kx[k]\\cdot h[n-k] $，其中$x[n]$为输入信号，$h[n]$为单位响应。所以输出即为输入的延迟相应叠加，即本质为加权积分。\n\n     二维信号的卷积：$ y[m,n]=x[m,n]*h[m,n]=\\sum_i\\sum_jx[i,j]\\cdot h[m-i,n-j] $，引入了卷积核的概念，对应于一维卷积中的单位响应。因此，二维卷积也是加权积分，但是其中卷积核进行了水平和竖直方向的翻转，可以定义为转置卷积。\n\n     卷积核具有局部性的属性，它仅关注于局部特征，局部的范围取决于卷积核的大小。图像与卷积核卷积的过程即为对图像的频域信息进行选择的过程。图像中边缘和轮廓属于高频信息，区域强度属于低频信息，这种理论指导了如何设计卷积核。\n\n     在卷积神经网络中，每一层之间的卷积核参数是固定的，且会多一个偏置参数，提升非线性因素，所以在卷积网络中由于卷积核和偏置是固定的，相比于神经网络大大降低了参数数量。卷积核中的参数是通过梯度优化得到的，所以参数的初始化就显得尤为重要。\n\n     **池化：**池化的本质就是采样，选择某种方式对特征进行压缩。可以减少参数数量，降低特征维度，有效减少后续网络层所需要的参数。其次可以增强特征的旋转或者位移不变性，增强网络的鲁棒性。\n\n6. ResNet和GoogleNet的原理。\n\n  **ResNet**的本质就是降低了数据中信息的冗余度。具体说来，就是对非冗余信息采用了线性激活（通过skip connection获得无冗余的identity部分），然后对冗余信息采用了非线性激活（通过ReLU对identity之外的其余部分进行信息提取/过滤，提取出的有用信息即是残差）。其中，提取identity这一步，就是ResNet思想的核心。 由于identity之外的其余部分的信息冗余度较高，因此在对其使用ReLU进行非线性激活时，丢失的有用信息也会较少，ReLU层输出为0的可能性也会较低。这就降低了在反向传播时ReLU的梯度消失的概率，从而便于网络的加深，以大大地发挥深度网络的潜能。 其次，特征复用能加快模型的学习速度，因为参数的优化收敛得快（从identity的基础上直接学习残差，总比从头学习全部来得快）。 \n\n     **GoogleNet**以降低参数为目的，利用全局平均池化层代替了全连接层，其次大量使用了$1\\times1$的卷积核。Inception结构中，每一层中拥有多个卷积核，但在同一位置中不同通道下的卷积核输出结果相关性极高。$1\\times1$的卷积核可以把这些相关性高、同一位置、不同通道下的特征结合起来。$3\\times3$，$5\\times5$的卷积核可以保证特征多样性。$1\\times1$卷积核在实现多个特征图的结合，整合不同通道间的信息的同时，可以实现升维和降维的效果。\n\n7. 一个二维数组中每一行和每一列都是以升序排列，用最快的方法找出某个值。\n\n  ```c++\n  vector<int> searchMatrix(vector<vector<int>> &matrix, int target)\n  {\n    vector<int> res;\n    if (matrix.empty() || matrix[0].empty())\n      return res;\n    int rows = matrix.size();\n    int cols = matrix[0].size();\n    int row = 0, col = cols-1;\n    while (row < rows && col >= 0)\n    {\n      if (matrix[row][col] == target)\n      {\n        res.push_back(row);\n        res.push_back(col);\n        return res;\n      }\n      else if (matrix[row][col] > target)\n      {\n        col--;\n      }\n      else\n      {\n        row++;\n      }\n    }\n    return res;\n  }\n  ```\n\n    \n\n1. A字符串中含有大量字符，B字符串中含有不超过100的少量字符，C字符串中也包含不超过100的少量字符，B字符串的长度与C的长度不一定相等。问题：从A中找出所有与B相同的子串，并将其替换为C。\n\n  \n\n  [KMP算法](https://blog.csdn.net/v_july_v/article/details/7041827)\n\n  ```c++\n  #include <iostream>\n  #include <vector>\n  #include <string>\n  \n  using namespace std;\n  \n  void GetNext(string p, vector<int> &next)\n  {\n      /**\n       * kmp算法中，先建立匹配字符串的next数组\n       * 即找数组中以某个点为终止的子字符串的前缀后缀最大公共长度\n       * 而next数组就是将最大公共长度的数值向右移一位\n       * 第一个元素为-1\n       * ABCDABD\n       * ->\n       * 0,0,0,0,1,2,0（最大公共长度数组）\n       * ->\n       * -1,0,0,0,0,1,2（next数组）\n       */\n  \n      int p_len = p.length();\n      next[0] = -1;\n      int k = -1;\n      int j = 0;\n      while (j < p_len-1)\n      {\n          if (k == -1 || p[j] == p[k])\n          {\n              k++;\n              j++;\n              if (p[j] != p[k])\n                  next[j] = k;\n              else\n                  next[j] = next[k];\n          }\n          else\n          {\n              k = next[k];\n          }\n      }\n  }\n  \n  vector<int> KmpSearch(string a, string b)\n  {\n      /**\n       * kmp算法去找匹配字符串在原字符串的起点位置\n       */\n  \n      vector<int> index;\n      int big_len = a.length();\n      int small_len = b.length();\n      int i = 0, j = 0;\n      vector<int> next(b.length(), 0);\n      GetNext(b, next);\n      while (i < big_len && j < small_len)\n      {   \n          if (j == -1 || a[i] == b[j])\n          {\n              i++;\n              j++;\n          }\n          else\n          {\n              //如果当前元素不匹配，将匹配字符串的位置回退到前一子字符串的公共前缀的后一个元素\n              j = next[j];\n          }\n  \n          if (j == small_len)\n          {\n              index.push_back(i-j);\n              j = 0;\n          }\n      }\n      return index;\n  }\n  \n  vector<int> NormalSearch(string a, string b)\n  {\n      /**\n       * 传统方法去找匹配字符串在原字符串的起点位置\n       */\n  \n      vector<int> index;\n      int big_len = a.length();\n      int small_len = b.length();\n      int i = 0, j = 0;\n      while (i < big_len && j < small_len)\n      {\n          if (a[i] == b[j])\n          {\n              i++;\n              j++;\n          }\n          else\n          {\n              i++;\n              j = 0;\n          }\n  \n          if (j == small_len)\n          {\n              index.push_back(i-j);\n              j = 0;\n          }\n      }\n      return index;\n  }\n  \n  string Kmp(string a, string b, string c)\n  {\n      vector<int> index = KmpSearch(a, b);\n      // vector<int> index = NormalSearch(a, b);\n      string res = \"\";\n      int change_index = 0;\n      int i = 0;\n      for ( ; i < a.length(); i++)\n      {\n          if (i == index[change_index])\n          {\n              for (int j = 0; j < c.length(); j++)\n              {\n                  res += c[j];\n              }\n              i += b.length()-1;\n              change_index++;\n              if (change_index == index.size())\n                  break;\n          }\n          else\n          {\n              res += a[i];\n          }\n      }\n      while (i < a.length())\n      {\n          res += a[i++];\n      }\n      return res;\n  }\n  \n  int main(int argc, char const *argv[])\n  {\n      string a = \"eiqwuhfiqwheofsalknfa*yanganzhe*ashifeqwnfanzhejfoiaejwor*yanganzhe*idasho\";\n      string b = \"yanganzhe\";\n      string c = \"Avery\";\n  \n      cout << \"原字符串: \" << a << endl;\n  \n      string res = Kmp(a, b, c);\n      cout << \"新字符串: \" << res;\n      return 0;\n  }\n  \n  ```\n\n  \n\n2. 说一下对反向传播的理解。\n\n   \n\n   神经网络的目的就是拟合，即给定一些样本点，通过合适的函数曲线去拟合关系变化。学习的目的就是通过调整函数中的参数，使得最终所得的结果与预想的结果之间的差距越来越小。大多数的实际问题都是非凸的，即存在很多局部最小值，通过简单的梯度下降方法就可以有效求解出最优结果。其中链式法则在高维情况时就变成了Jacobian矩阵乘法。\n\n3. 介绍下Adam优化方法。\n\n  \n\n  结合了动量法和RMSprop的特征，增加了自适应学习率\n\n4. 如何防止过拟合效应？有哪些方法。\n\n   \n\n   引入正则化、Dropout使神经元随机失活、增加样本数量、提前终止训练、加入BN层。\n\n5. 如何防止梯度爆炸和梯度消失？\n\n   \n\n   预训练加微调、权重正则化、ReLU激活函数、加入BN层、引入残差结构。\n\n   梯度剪切（设置一个梯度剪切阈值，更新梯度时如果超过这个阈值，那么就限制在这个范围之内，防止梯度爆炸）\n\n   LSTM（每次更新参数时，单元会保存前几次训练的残留记忆，会对当前更新过程产生影响）\n\n6. ResNet中是如何防止梯度爆炸或消失的问题的？\n\n  \n\n  使用ReLU激活函数、使用跳跃连接。\n\n7. $1*1$卷积核的作用。\n\n  \n\n  可以起到一个跨通道聚合特征的作用，同时可以起升维和降维的作用。\n\n8. 在实验中是如何解决损失值不收敛的问题？\n\n  \n\n  对数据做归一化、检查梯度、对数据进行预处理、使用正则化、Batch Size太大、学习率太大或太小、激活函数不适合、梯度消失问题、参数初始化问题（面试官和我讨论了很久，他说权重初始化并不影响损失的收敛）、网络太深。\n\n9. 有三个球筒A、B、C，每个筒都包含三种不同颜色的球，分别为红色、蓝色、白色，每个筒中每个颜色球的个数为$r_i,b_i,w_i(i=1,2,3)$，问题：从所有筒中抽取一个球，结果为红色，求其属于A筒的概率。\n\n   \n\n   所有颜色球的总数为：$ sum=\\sum r_i+\\sum b_i+\\sum w_i $\n\n   红色球的概率为：$ p_r=\\sum r_i/sum $\n\n   蓝色球的概率为：$ p_b=\\sum b_i/sum $\n\n   白色球的概率为：$ p_w=\\sum w_i/sum $\n\n   球属于A筒的概率为：$ p_A=(r_1+b_1+w_1)/sum $\n\n   球属于B筒的概率为：$ p_B=(r_2+b_2+w_2)/sum $\n\n   球属于C筒的概率为：$ p_C=(r_3+b_3+w_3)/sum $\n\n   第i个筒中红球的概率为：$ p(r|i)=r_i/(r_i+b_i+w_i) $\n\n   第i个筒中蓝球的概率为：$ p(b|i)=b_i/(r_i+b_i+w_i) $\n\n   第i个筒中白球的概率为：$ p(w|i)=w_i/(r_i+b_i+w_i) $\n\n   从所有筒中抽取一个球，结果为红色，对应于A筒的概率为：（贝叶斯公式）\n\n   $$ p(A_i|B)=\\frac{p(B|A_i)p(A_i)}{\\sum_ip(B|A_i)p(A_i)} $$\n\n   $$ p(tube=A|ball=red)=\\frac{P_{ball=red|tube=A}\\cdot P_{tube=A}}{\\sum_{A,B,C}P_{ball=red|tude=i}\\cdot P_{tude=i}}=\\frac{p(r|A)\\cdot p(A)}{p(r|A)\\cdot p(A)+p(r|B)\\cdot p(B)+p(r|C)\\cdot p(C)} $$\n\n   即结果为：$ \\frac{r_1}{r_1+r_2+r_3}$\n\n10. 了解过哪些机器学习方法。\n\n   \n\n   逻辑回归、支持向量机、决策树、主成分分析。\n","tags":["Method Summary"]},{"title":"Accurate Tracking by Overlap Maximization","url":"/2019/05/14/Accurate-Tracking-by-Overlap-Maximization/","content":"\n论文链接：[Danelljan M, Bhat G, Khan F S, et al. ATOM: Accurate Tracking by Overlap Maximization[J]. arXiv preprint arXiv:1811.07628, 2018.](https://arxiv.org/abs/1811.07628)\n\n### 前言\n\n本文的主要思想是通过状态估计网络优化目标位置，提升跟踪精度；通过分类网络区分前景和背景，提升跟踪准确率。前者是通过大规模数据集进行离线训练的，后者是通过改进的GN梯度下降策略在线学习的。\n\n### 背景\n\n在单目标跟踪领域，最近的改进主要是针对于算法鲁棒性方面，也就是提升了跟踪目标的中心点和类别的预测准确性，但在预测目标框的精确性方面没有太多的进展，只是简单的使用多个尺度系数来找到最适合的尺度框，作为最终的预测尺度。跟踪目标在运动过程中可能会发生姿态变化，物体的长宽比会发生较大的改变，单纯的计算某个尺度系数并不能较好的表示目标的精确位置。\n\n在本文中尝试将跟踪任务分为物体分类和位置估计两部分，并通过两个网络分支分别计算不同的任务，最后融合这两个任务构建一个全新的多任务跟踪网络模型。本文算法在NFS、UAV123、TrackingNet和VOT2018四个跟踪数据集上进行了实验，成为了新的领头羊，并在UAV123数据集上取得了11%的提升。\n\n### 创新点\n\n- 离线训练IoU网络，将预测位置框进一步精确\n- 使用创新的梯度优化策略，提升梯度下降的速度，在线学习基于目标的分类器\n\n<center>{% asset_img 1.png 800 500 整体网络模型 %}</center>\n\n#### 位置估计分支\n\n本文中使用改进IoU-Net来对预测的位置进一步精确，主要分为以下几个部分：\n\n- 输入图像的深度特征$ x\\in \\mathbb{R}^{W\\times H\\times D} $和标定的目标位置$ B\\in \\mathbb{R}^4 $$ (Cx/w, Cy/h, \\log{w}, \\log{h}) $，并使用Precise ROI Pooling层对特征进行池化，该层可视为一个关于坐标值的可微连续函数，因此可以通过最大化IoU目标函数进行优化\n- 相比于检测任务，跟踪任务的目标类别是未知的，而且在图像中仅有前景和背景两个类别，因此需要对IoU-Net进行改进，使其变为基于目标的位置估计，改进后的结果如图，基本网络为ResNet-18\n\n<center>{% asset_img 2.png 800 500 位置估计分支 %}</center>\n\n- 第一个分支提取第一帧的目标信息，输入图像特征和目标位置，输出modulation vector$ (1\\times1\\times D_z) $；第二个分支提取当前帧的图像信息，在全连接层之前，要将池化层的输出和上一分支的modulation vector进行channel-wise相乘，得到与第一帧目标信息相关的modulation vector$ (K\\times K\\times D_z) $，之后再通过一个全连接层得到最终的IoU预测值，即$ IoU(B)=g(c(x_0,B_0)\\cdot Z(x,B)) $\n- 该网络可以使用带有标注信息的视频进行端到端的训练，本文中使用LaSOT、TrackingNet和COCO数据集进行训练，训练时图中reference image为目标大小的25倍，对于每一个图像对，在坐标上加入高斯噪声使其产生16个区域来进行训练，测试图像是在原有目标图像的基础上进行了尺度和位置的随机扰动而进行的\n- 基础网络ResNet的参数是不变的，使用MSE Loss作为目标函数，batch-size设置为64，并使用Adam梯度优化迭代40个周期，学习率设置为0.01并每隔15个周期学习率变化0.2倍\n\n#### 物体分类分支\n\n通过位置估计分支可以得到目标的精确位置，但由于缺乏类别信息，并不能对目标和干扰物进行有效区分，因此需要在线训练一个分类器来完成此任务，主要目的是提供物体的粗略位置，提升网络的辨别能力并最小化错误检测率，尺度为上一帧预测的尺度大小，具体过程如下：\n\n- 在第一帧视频图像中，对图像进行旋转、模糊等数据增强方法得到30个训练样本\n- 设计一个由两层全卷积层组成的分类器，输入为ResNet提取的图像特征，输出为热度图\n\n$$ f(x;\\omega)=\\phi_2(\\omega_2*\\phi_1(\\omega_1*x)) $$\n\n- 损失函数为$ L(\\omega)=\\sum^m_{j=1}\\gamma_j|f(x_j;\\omega)-y_j|^2+\\sum_k\\lambda_k|\\omega_k|^2 $，其中$j\\in(1,2,…,30),k\\in(1,2)$\n- 由于常规梯度优化方法学习速度较慢，无法满足在线学习和实效性的需求，本文中设计了一种新的梯度优化方法，将上式中的两项用残差来统一表示，转化为$ r_j(\\omega)=\\sqrt{\\gamma_j}(f(x_j;\\omega)-y_j),r_{30+k}(\\omega)=\\sqrt{\\lambda_k}\\omega_k $\n- 通过残差表示的方法可以将损失函数转化为$ L(\\omega)=|r(\\omega)|^2 $，并根据高斯牛顿近似忽略二阶微分可得$ \\tilde{L}_\\omega\\approx L(\\omega+\\Delta\\omega) $，之后在$ \\omega+\\Delta\\omega $处将$ r(\\omega) $函数展开，即$ r(\\omega+\\Delta\\omega)\\approx r_\\omega+J_w\\Delta\\omega $，这样就可以把损失函数展开，表示为$ \\tilde{L}_w=\\Delta\\omega^TJ_\\omega^TJ_\\omega\\Delta\\omega+2\\Delta\\omega^TJ_\\omega^Tr_\\omega+r_\\omega^Tr_\\omega $，此处$ r_\\omega=r(\\omega),J_\\omega=\\frac{\\partial r}{\\partial \\omega} $，我们需要的就是通过$ \\Delta\\omega $来更新参数$ \\omega $，这里可以直接求$ L(\\omega+\\Delta\\omega)-L(\\omega) $对$ \\Delta\\omega $的梯度即可，本文中作者采用PyTorch中的反向传播并通过简单的代码巧妙的解决了这一问题，改进的梯度优化策略如下\n\n<center>{% asset_img 3.png 700 500 改进的梯度优化策略 %}</center>\n\n### 跟踪过程\n\nATOM算法通过PyTorch实现，在GTX1080的GPU上速度为30fps。\n\n基本网络ResNet-18为在ImageNet数据集上与训练的网络，使用block3和block4的输出作为图像特征，图像输入尺寸为$ 288\\times288 $。\n\n在物体分类分支中，提取图像特征后，首先经过一个$ 1\\times1 $的卷积层使特征降至64维度，以此来减小内存占用和计算量，之后一个卷积层的卷积核为$ 4\\times4 $，并使用PELU$ =\\begin{cases} t & t\\ge0 \\\\ \\alpha(e^{\\frac{t}{\\alpha}}-1) & t<0 \\end{cases}$激活函数。\n\n在目标估计分支中，通过分类分支得到一个粗略的目标位置，尺度为上一帧的尺度大小，之后在此坐标位置上增加随机噪声得到10个建议框，然后根据IoU通过5次梯度下降来分别优化每个建议框，取IoU值最高的前三个目标框的平均值作为最终的预测结果。\n\nHard Negative Mining: 如果在当前帧的热度图中出现了干扰峰，将学习率加倍并对分类器诶进行一轮优化，当分数低于0.25时判定为目标丢失。\n\n### 实验结果\n\n- 作者对比了在IoU-Net中移除reference分支，性能下降了5.5%；之后对比了Baseline网络和Siamese网络，结果是Siamese网络更优；最后对比了使用Block3和Block4的特征有效性，结果为融合两层特征更好。\n\n<center>{% asset_img 7.png 500 100 IoU分支对比实验 %}</center>\n\n- 在位置估计方面对比了多尺度系数查询和IoU的方法，在物体分类方面对比了GD、GD++以及本文的GN方法，结果为GN方法更好，而且还说明了增加梯度优化次数并不能提升算法性能。\n\n<center>{% asset_img 8.png 500 100 分类器对比实验2 %}</center>\n\n- NFS、UAV123、TrackingNet、VOT2018四个数据集的结果如图\n\n<center>{% asset_img 4.png 600 300 NFS、UAV123结果图 %}</center>\n\n<center>{% asset_img 5.png 600 100 TrackingNet结果图 %}</center>\n\n<center>{% asset_img 6.png 600 100 VOT2018结果图 %}</center>\n\n### 总结\n\n最近基于单目标跟踪的算法都是集中在对Siamese网络模型的各种创新上，致力于提升分类器的判别性能，而忽略了目标状态估计的重要性。本文从bounding-box的精确性角度出发，构建了位置估计分支，为了提升判别性能构建了物体分类分支，并进行了多任务的融合，在多个数据集上达到了最好的效果。本文作者在分析问题的时候能挖掘别人没有注意到的地方，如之前优化KCF时作者提出DSST通过滤波器计算合适的尺度从而提升性能。\n","tags":["Paper Review"]},{"title":"K-means Clustering","url":"/2019/04/18/K-Means-Clustering/","content":"\n> k-means算法源于信号处理中的一种向量量化方法，现作为一种聚类分析方法。它的目的是把每个数据点划分到k个聚类中心范围里，使得每个点都属于离它最近的聚类中心对应的类别。\n\n### 算法描述\n\n已知数据集$(x_1,x_2,…,x_n)$，其中每个数据都是一个$p$维特征向量，k-means 算法就是要把这些输入数据划分到 k 个类别集合$S_i$中，目标函数为：\n\n$$ \\underset{S}{\\mathrm{argmin}}\\sum^k_{i=1}\\sum_{x\\in S_i}\\Arrowvert x-\\mu_i\\Arrowvert^2 $$\n\n其中$\\mu_i$是$S_i$中所有点的均值。\n\n聚类中心的更新函数为：\n\n$$ k_i=\\frac{1}{\\mid S_i\\mid}\\sum_{x\\in S_i}x $$\n\n由于上述最小化问题是一个 [NP 困难]([https://zh.wikipedia.org/wiki/NP%E5%9B%B0%E9%9A%BE](https://zh.wikipedia.org/wiki/NP困难))问题，因此只能采用启发式迭代方法来进行求解。\n\n### 算法步骤\n\n```markdown\n选择 k 个数据点作为初始聚类中心\nRepeat\n\t\t计算每个数据点到聚类中心的距离，并将其划分为离它最近的类别中，形成 k 个簇\n\t\t根据目标函数重新计算每个类别的聚类中心\nUntil 聚类中心不发生变化或达到最大迭代此数\n```\n\n**优点：**原理简单，易于实现，可解释度较高，参数仅有聚类中心个数 k\n\n**缺点：**初始化聚类中心的选取不好把握，可能收敛于局部极值，且在大规模数据中收敛速度较慢，对异常点比较敏感\n\n### 距离度量\n\n**欧式距离**\n\n$$ d=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2} $$\n\n**曼哈顿距离**\n\n$$ d=\\mid x_1-x_2\\mid+\\mid y_1-y_2\\mid $$\n\n**切比雪夫距离**\n\n$$ d=\\max(\\mid x_1-x_2\\mid,\\mid y_1-y_2\\mid) $$\n\n**余弦距离**\n\n$$ d=\\frac{x_1x_2+y_1y_2}{\\sqrt{(x_1+y_1)^2}\\sqrt{(x_2+y_2)^2}} $$\n\n### 代码实现\n\n```java\npublic class KMeans {\n\n    public double[][][] kmeans(double[][] data, int k, int epoch, double error) {\n        int n = data.length;//数据个数\n        int p = data[0].length;//每个数据的特征个数\n\n        //初始化聚类中心\n        double[][] kCenter = new double[k][p];\n        for (int i = 0; i < k; i++) {\n            for (int j = 0; j < p; j++) {\n                kCenter[i][j] = data[i][j];\n            }\n        }\n\n        double[][][] temp = new double[k][n][p];\n\n        //聚类之后的结果，三维数组，第一维度为类别个数，第二维度为数据个数，第三维度为特征个数\n//        double[][][] resData = new double[k][n][p];\n\n        //定义每种类别的样本个数\n//        int[] numOfCi = new int[k];\n\n        //迭代epoch次\n        for (int iter = 0; iter < epoch; iter++) {\n\n            double[][][] resData = new double[k][n][p];\n            int[] numOfCi = new int[k];\n\n            //将数据聚类到离它最近的聚类中心类别中\n            for (int i = 0; i < n; i++) {\n                double minDistance = Double.MAX_VALUE;\n                int minDisIndex = 0;\n                for (int j = 0; j < k; j++) {\n                    double curDistance = distance(kCenter[j], data[i]);\n                    if (curDistance < minDistance) {\n                        minDistance = curDistance;\n                        minDisIndex = j;\n                    }\n                }\n                resData[minDisIndex][numOfCi[minDisIndex]++] = data[i];\n            }\n\n            //重新计算聚类中心\n            for (int i = 0; i < k; i++) {\n                for (int j = 0; j < p; j++) {\n                    double eachDataP = 0;\n                    for (int d = 0; d < numOfCi[i]; d++) {\n                        eachDataP += resData[i][d][j];\n                    }\n                    kCenter[i][j] = eachDataP / numOfCi[i];\n                }\n            }\n\n            //计算目标函数，若小于设定值则退出迭代\n            double curError = 0.0;\n            for (int i = 0; i < k; i++) {\n                for (int j = 0; j < numOfCi[i]; j++) {\n                    curError += distance(resData[i][j], kCenter[i]);\n                }\n            }\n            if (curError < error) {\n                return resData;\n            }\n\n            if (iter+1 == epoch) {\n                return resData;\n            }\n        }\n\n        return temp;\n    }\n\n    public double distance(double[] x, double[] y) {\n        int feaLen = x.length;\n        double dis = 0;\n        for (int i = 0; i < feaLen; i++) {\n            dis += Math.pow(x[i] - y[i], 2);\n        }\n        dis = Math.sqrt(dis);\n        return dis;\n    }\n\n    public static void main(String[] args) {\n        KMeans kMeans = new KMeans();\n        double[][] data = {\n                {1.0, 2.0},\n                {2.0, 7.0},\n                {3.0, 1.0}\n        };\n        int k = 2;\n        int epoch = 3;\n        double error = 0.0;\n        double[][][] res = kMeans.kmeans(data, k, epoch, error);\n        for (int i = 0; i < k; i++) {\n            System.out.println(\"Category \"+i+\" :\");\n            for (int j = 0; j < res[i].length; j++) {\n                for (int f = 0; f < res[i][j].length; f++) {\n                    if (res[i][j][f] != 0.0) {\n                        System.out.print(res[i][j][f]);\n                        System.out.print(\" \");\n                    }\n                }\n                System.out.println();\n            }\n        }\n    }\n}\n```\n\n### 优化算法\n\n#### k-means++\n\n**动机：**初始化聚类中心对之后的聚类结果和运行速度都有着很大的影响，因此初始化合适的聚类中心就很有必要。\n\n**策略：**\n\n1. 从输入数据集合中随机选择一个点作为第一个聚类中心$c_1$\n2. 计算每一个数据与已选择聚类中心的距离，并找到最短距离，代表了当前样本与当前已有聚类中心之间最短的距离，即$d(x_i)={\\mathrm{argmin}}||x_i-c_s||^2_2$    $s=1,2,…,c_{selected}$\n3. 每个数据被选择为聚类中心的可能性为$\\frac{d(x)^2}{\\sum_{x_i\\in X}d(x)^2}$，选择其中具有最大概率的数据点作为下一个聚类中心\n4. 重复2、3步选择出 k 个聚类中心，并使用这些点作为初始话的聚类中心执行 k-means 算法\n\n#### mini batch k-means\n\n**动机：**若输入数据量特别大，那么每次都要计算所有数据点到聚类中心的距离，导致算法非常耗时。\n\n**策略：**\n\n1. 从数据集中选择一部分数据执行 k-means 算法，批样本大小为 batch size\n2. 批样本大小一般通过无放回的随机抽样得到的\n3. 为了提升算法的准确性，一般选择多个 batch size 执行多次 k-means 算法，选择其中最优的聚类中心\n\n\n\n","tags":["Machine Learning"]},{"title":"Support Vector Machine","url":"/2019/03/20/Support-Vector-Machine/","content":"\n> SVM(Support Vector Machine)，即支持向量机，是一种广泛应用的以监督学习为模式的分类算法。它以边界为出发点，通过最大化边界距离来完成数据分类工作，并使用拉格朗日进行优化，核函数的引入赋予了SVM分类高维特征的力量，最终通过SMO算法有效的实施了SVM的思想。\n\n### SVM理论部分\n\n#### 边界概念的引入(Margins)\n\n由逻辑回归可知，$p(y=1|x;\\theta)​$的概率由$h_\\theta(x)=g(\\theta^Tx)​$决定，如果$g(\\theta^Tx)\\ge0.5​$，即$\\theta^Tx\\ge0​$，则将被预测为1。所以说$\\theta^Tx​$越大，$h_\\theta(x)​$就越大，即$\\theta^Tx\\gg0​$时可以认定$y=1​$，$\\theta^Tx\\ll0​$时可以认定$y=0​$。\n\n<center>{% asset_img 1.png 300 300 决策边界 %}</center>\n\n上图中，x表示正样本，o表示负样本，中间的分界线即为决策边界(decision boundary)，也就是$\\theta^Tx=0$所划分的线，图中有三个点A、B、C。\n\nA点离决策边界很远，基本上会被分类为正样本，而C点离决策边界很近，很大可能被误分类为负样本。所以说，我们会对A的分类结果很自信，而对于C的分类结果就会产生怀疑。\n\n所以，当给定一组数据进行分类时，我们希望决策边界不光能将数据分类正确，还希望每一个数据都离决策边界非常远，这样就能确信我们的分类结果时正确的。这就是所谓的决策边界。\n\n\n\n#### 赋予数据标记\n\n定义类别标签为$y\\in\\{-1,1\\}$，用参数$\\omega,b$代替线性分类器中的参数$\\theta$，则决策函数为：\n\n$$ h_{\\omega,b}(x)=g(\\omega^Tx+b)=\\left\\{\\begin{aligned}1&  \\ z\\ge0 \\\\ 0 & \\ z<0 \\end{aligned}\\right. ​$$\n\n符号$b$代替了$\\theta_0$，符号$\\omega$代替了$[\\theta_1…\\theta_n]^T$，为了一致性，将$x_0=1$加入到输入特征中。\n\n\n\n#### 边界的函数性(Functional)和几何性(Geometric)\n\n**函数边界**\n\n给定一个训练样本$(x^{(i)},y^{(i)})$，定义函数性边界为：\n\n$$ \\hat{\\gamma}^{(i)}=y^{(i)}(\\omega^Tx+b) ​$$\n\n当$y^{(i)}(\\omega^Tx+b)>0​$时，说明预测结果是正确的。当函数性边界非常大时，说明此分类模型性能十分好，即：\n\n当$y^{(i)}=1$时，为了让函数性边界非常大，需要$\\omega^Tx+b$返回一个非常大的正数值；当$y^{(i)}=-1$时，为了让函数性边界非常大，需要$\\omega^Tx+b$返回一个非常小的负数值。\n\n如果仅是将参数$\\omega,b$扩大任意尺度，并不会改变$h_{\\omega,b}(x)$的值，所以对它们进行任意尺度变化，并不会改变最终的分类性能。\n\n最终的$\\hat{\\gamma}​$为所有训练集中最小的$\\hat{\\gamma}^{(i)}​$。\n\n\n\n**几何边界**\n\n<center>{% asset_img 2.png 300 300 几何边界 %}</center>\n\n其中，图中A点为正样本，它到决策边界的距离$ \\gamma^{(i)}​$是直线段AB的长度。如何去求$ \\gamma^{(i)}​$的值呢？\n\n$ \\frac{\\omega}{\\parallel \\omega\\parallel} $是一个单位长度的向量，与$ \\omega $具有相同的方向。假设A点代表$ x^{(i)} $，且B点可以通过$x^{(i)}-\\gamma^{(i)}\\cdot\\frac{\\omega}{\\parallel \\omega\\parallel}$来得到。其中B点在决策边界上，所有在决策边界上的数据都满足$w^Tx+b=0$的条件，因此可以得到：\n\n$$ w^T(x^{(i)}-\\gamma^{(i)}\\frac{\\omega}{\\parallel \\omega\\parallel})+b=0 $$\n\n求解$\\gamma^{(i)}$，结果为：\n\n$$ w^Tx^{(i)}+b=\\gamma^{(i)}\\frac{w^Tw}{\\parallel \\omega\\parallel}=\\gamma^{(i)}\\frac{\\parallel \\omega\\parallel^2}{\\parallel \\omega\\parallel} $$\n\n$$ \\gamma^{(i)}=\\frac{w^Tx^{(i)}+b}{\\parallel \\omega\\parallel}=(\\frac{\\omega}{\\parallel \\omega\\parallel})^Tx^{(i)}+\\frac{b}{\\parallel \\omega\\parallel} $$\n\n给定一个训练样本$(x^{(i)},y^{(i)})​$，定义几何性边界为：\n\n$$ \\gamma^{(i)}=y^{(i)}((\\frac{\\omega}{\\parallel\\omega\\parallel})^Tx^{(i)}+\\frac{b}{\\parallel\\omega\\parallel}) ​$$\n\n其中当$\\parallel\\omega\\parallel=1​$时，几何性边界和函数性边界一致，通过这种方式将两种边界联合在一起。\n\n\n\n####  边界的优化\n\n如何最大化决策边界，可以通过以下优化方法：\n\n$$ max_{\\gamma,\\omega,b}\\ \\ \\ \\gamma ​$$\n\n$$ s.t.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ y^{(i)}(\\omega^Tx^{(i)}+b)\\ge\\gamma,\\ \\ i=1,…,m​$$\n\n$$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\parallel w\\parallel=1 ​$$\n\n然而，由于$\\parallel w\\parallel=1​$的限制，使得此问题是一个非凸优化，无法使用标准优化方法去求解。为了更好的求解，将上式转变为：\n\n$$ max_{\\hat{\\gamma},\\omega,b}\\ \\ \\ \\frac{\\hat{\\gamma}}{\\parallel \\omega\\parallel} ​$$\n\n$$ s.t.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ y^{(i)}(\\omega^Tx^{(i)}+b)\\ge\\hat{\\gamma},\\ \\ i=1,…,m​$$\n\n从此，优化问题转变为最大化$\\frac{\\hat{\\gamma}}{\\parallel \\omega\\parallel} $，并且消除了$\\parallel w\\parallel=1$的限制。但是目标函数$\\frac{\\hat{\\gamma}}{\\parallel \\omega\\parallel} $仍然是一个非凸优化问题。\n\n由于对参数$\\omega,b$可以进行任意尺度的变化，且不影响最终分类器性能。那么我们可以引入一个比例约束，通过限制参数$\\omega,b$使得训练集的函数边界为1，即$\\hat{\\gamma}=1$。\n\n那么最大化$\\frac{\\hat{\\gamma}}{\\parallel \\omega\\parallel}$就可以转化为最大化$\\frac{1}{\\parallel \\omega\\parallel}$，也就等于最小化$\\parallel \\omega\\parallel^2$，即：\n\n$$ min_{\\omega,b}\\ \\ \\ \\ \\ \\ \\frac{1}{2}\\parallel \\omega\\parallel^2 ​$$\n\n$$ s.t.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ y^{(i)}(\\omega^Tx^{(i)}+b)\\ge1,\\ \\ i=1,…,m​$$\n\n这样就把无法优化的问题有效的解决了，上式是一个线性约束的二次凸优化问题，给予了我们解决优化边界分类器的方法。接下来使用拉格朗日方法去解决这个问题。\n\n\n\n#### 拉格朗日算子\n\n拉格朗日乘法是为了解决如下问题：\n\n$$ min_\\omega\\ \\ \\ f(\\omega) $$\n\n$$ s.t.\\ \\ \\ \\ \\ h_i(\\omega)=0,\\ \\ i=1,…,l. $$\n\n1. 定义拉格朗日式为：\n\n$$ \\mathcal{L}(\\omega,\\beta)=f(\\omega)+\\sum^l_{i=1}\\beta_ih_i(\\omega) ​$$\n\n其中，$\\beta_i$称为拉格朗日乘数。\n\n2. 将$\\mathcal{L}$的偏导设为零，求解参数$\\omega,\\beta$：\n\n$$ \\frac{\\partial{\\mathcal{L}}}{\\partial{\\omega_i}}=0,\\frac{\\partial{\\mathcal{L}}}{\\partial{\\beta_i}}=0 $$\n\n\n\n**对偶问题**\n\n假设要优化以下问题，称之为 **primal** 问题：\n\n$$ min_{\\omega}\\ \\ \\ \\ \\ \\ \\ \\ \\ f(\\omega) $$\n\n$$ s.t.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ g_i(\\omega)\\le0,\\ \\ i=1,…,k$$\n\n$$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ h_i(\\omega)=0,\\ \\ i=1,…,l. $$\n\n首先定义拉格朗日式为：\n\n$$ \\mathcal{L}(\\omega,\\alpha,\\beta)=f(\\omega)+\\sum^k_{i=1}\\alpha_ig_i(\\omega)+\\sum^l_{i=1}\\beta_ih_i(\\omega) ​$$\n\n其中，$\\alpha_i,\\beta_i$为拉格朗日乘数。\n\n定义$\\theta_{primal}(\\omega)=\\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max}\\mathcal{L}(\\omega,\\alpha,\\beta)​$，给定某些$\\omega​$，如果违反了约束限制，则：\n\n$$ \\theta_{primal}(\\omega)=\\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max}f(\\omega)+\\sum^k_{i=1}\\alpha_ig_i(\\omega)+\\sum^l_{i=1}\\beta_ih_i(\\omega)=\\infty ​$$\n\n如果满足了约束条件，则$\\theta_{primal}=f(\\omega)$。所以，$\\theta_{primal}$ 在$\\omega$满足约束的时候与所要优化的问题拥有相同的结果，所以按照 primal 问题所示，得到以下最小化问题：\n\n$$ \\underset{\\omega}{min}\\ \\theta_{primal}=\\underset{\\omega}{min}\\ \\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max} \\mathcal{L}(\\omega,\\alpha,\\beta) ​$$\n\n它与 primal 优化问题一致。\n\n定义$\\theta_{dual}(\\alpha,\\beta)=\\underset{\\omega}{min}\\ \\mathcal{L}(\\omega,\\alpha,\\beta)$，上述 primal 问题是关于参数$\\alpha,\\beta$的最大化问题，而此问题是关于参数$\\omega$的最小化问题，如果加上 primal 问题的限制，变为 **dual** 优化问题：\n\n$$ \\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max}\\ \\theta_{dual}(\\alpha,\\beta)=\\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max}\\ \\underset{\\omega}{min}\\ \\mathcal{L}(\\omega,\\alpha,\\beta) ​$$\n\n这就转化为与 primal 问题加上最小化问题一致了，只是把最大化和最小化的位置进行了颠倒，然后 primal 和 dual 问题可以产生以下相关性：\n\n$$ \\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max}\\ \\underset{\\omega}{min}\\ \\mathcal{L}(\\omega,\\alpha,\\beta) \\ \\le\\ \\underset{\\omega}{min}\\ \\underset{\\alpha,\\beta:\\alpha_i\\ge0}{max} \\mathcal{L}(\\omega,\\alpha,\\beta) $$\n\n特殊情况下，上式取等号。\n\n基于以上假设，肯定存在参数$ \\omega^\\* $是 primal 问题的结果，$ \\alpha^\\* , \\beta^\\* $是 dual 问题的结果，或者存在同时是 primal 和 dual 两个问题的结果，只要它满足 KKT 条件，即：\n\n$$ \\frac{\\partial}{\\partial{\\omega_i}}\\mathcal{L}(\\omega^*,\\alpha^*,\\beta^*)=0,\\ \\ i=1,…,n ​$$\n\n$$ \\frac{\\partial}{\\partial{\\beta_i}}\\mathcal{L}(\\omega^*,\\alpha^*,\\beta^*)=0,\\ \\ i=1,…,l ​$$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\alpha^*_ig_i(\\omega^*)=0,\\ \\ i=1,…,k $$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ g_i(\\omega^*)\\le0,\\ \\ i=1,…,k $$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\alpha^*\\ge0,\\ \\ i=1,…,k $$\n\n这里隐含着一个条件，当$\\alpha>0$时，$g(\\omega^*)=0$。这是一个关键条件，表明支持向量机仅有少量的 support vectors。\n\n\n\n### 分类器的优化\n\n首先可以把边界的优化函数中约束条件改为：\n\n$$ g_i(\\omega)=1-y^{(i)}(\\omega^Tx^{(i)}+b)\\le0 $$\n\n则拉格朗日式为：\n\n$$ \\mathcal{L}(\\omega,b,\\alpha)=\\frac{1}{2}\\parallel \\omega\\parallel^2-\\sum^m_{i=1}\\alpha_i[y^{(i)}(\\omega^Tx^{(i)}+b)-1] ​$$\n\n为了优化此函数，需要先进行关于参数$\\omega,b​$的最小化$\\mathcal{L}​$工作，去得到$\\theta_{dual}​$，即求关于两个参数的偏导并置为零：\n\n$$\\bigtriangledown_\\omega\\mathcal{L}(\\omega,b,\\alpha)=\\omega-\\sum^m_{i=1}\\alpha_iy^{(i)}x^{(i)}=0​$$\n\n即$\\omega=\\sum^m_{i=1}\\alpha_iy^{(i)}x^{(i)}​$\n\n$$\\bigtriangledown_b\\mathcal{L}(\\omega,b,\\alpha)=\\sum^m_{i=1}\\alpha_iy^{(i)}=0$$\n\n即$\\sum^m_{i=1}\\alpha_iy^{(i)}=0$\n\n将以上结果代入原式：\n\n$$ \\mathcal{L}(\\omega,b,\\alpha)=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}y^{(i)}y^{(j)}\\alpha_i\\alpha_j(x^{(i)})^Tx^{(j)} ​$$\n\n这样我们得到关于参数$\\omega,b$的最小化的优化结果，将其与另两个约束条件结合，得到 dual 优化问题：\n\n$$ \\underset{\\alpha}{max}\\ Dual(\\alpha)=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}y^{(i)}y^{(j)}\\langle x^{(i)},x^{(j)}\\rangle ​$$\n\n$$ s.t.\\ \\ \\alpha_i\\ge0,\\ \\ i=1,…,m $$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\sum^m_{i=1}\\alpha_iy^{(i)}=0 ​$$\n\n最后，在分类预测的时候，给定输入数据$x$，通过上面求得的关于参数$\\omega$的等式，可得：\n\n$$ \\omega^Tx+b=(\\sum^m_{i=1}\\alpha_iy^{(i)}x^{(i)})^Tx+b=\\sum^m_{i=1}\\alpha_iy^{(i)}\\langle x^{(i)},x\\rangle+b $$\n\n其中，$\\langle x^{(i)},x\\rangle$是将训练集中每个点与输入数据$x$做内积，而有先前可知，仅仅当训练集中的数据是支持向量时，$\\alpha_i$才大于零，其它皆为零，所以可以忽略这些，仅考虑将输入数据与支持向量做内积即可，并且支持向量的个数是非常少的。\n\n\n\n#### 核函数\n\n将输入空间映射到另一个空间域的方法就是使用核函数，这种映射关系用$\\phi(x)$表示。给定一个特征映射函数$\\phi$，定义相关核为：\n\n$$ K(x,z)=\\phi(x)^T\\phi(z) $$\n\n即在算法中当遇到$\\langle x,z\\rangle$时可以用$K(x,z)$来代替。\n\n但是$K(x,z)​$的计算量很大，而且$\\phi(x)​$的计算量也很大。解决方法是我们可以让 SVM 直接在$\\phi​$的高维空间去学习，不需要去计算$\\phi(x)​$。\n\n如果$\\phi(x)$和$\\phi(z)$很相似，那么其$K(x,z)$值就会很大，否则则很小，那么就可以通过高斯很函数来判断它俩的相似性：\n\n$$ K(x,z)=exp(-\\frac{\\parallel x-z\\parallel^2}{2\\sigma^2}) $$\n\n当核矩阵是对称半正定时，可以说明$K$是一个有效的核。\n\n\n\n#### 正则化和不可分实例\n\n当得到一个决策边界时，如果加入一个数据会导致决策边界发生很大的变化，那么可能会导致不好的分类结果。为了解决此问题，不对那些异常值敏感，那么可以使用正则化方法：\n\n$$ min_{\\gamma,\\omega,b}\\ \\ \\ \\ \\ \\ \\frac{1}{2}\\parallel \\omega\\parallel^2+C\\sum^m_{i=1}\\xi_i,\\ \\ i=1,…,m $$\n\n$$ s.t.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ y^{(i)}(\\omega^Tx^{(i)}+b)\\ge1-\\xi_i,\\ \\ i=1,…,m$$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\xi_i\\ge0,\\ \\ i=1,…,m. $$\n\n此时，某些异常点被允许边界小于1，如果一个实例的函数边界为$1-\\xi_i$，可以对目标函数通过增加$C\\xi_i$来进行一个惩罚，参数$C$控制了相关权重与最小化$\\parallel \\omega\\parallel^2$的关系，确保大部分实例数据的函数边界至少为1。\n\n以上，可以把拉格朗日式改为：\n\n$$ \\mathcal{L}(\\omega,b,\\xi,\\alpha,r)=\\frac{1}{2}\\parallel \\omega\\parallel^2+C\\sum^m_{i=1}\\xi_i-\\sum^m_{i=1}\\alpha_i[y^{(i)}(\\omega^Tx^{(i)}+b)-1+\\xi_i]-\\sum^m_{i=1}r_i\\xi_i $$\n\n其中，参数$\\alpha_i,r_i$是拉格朗日乘子，约束其必须大于等于零。\n\n求偏导之后，所得的 dual 优化问题为：\n\n$$ \\underset{\\alpha}{max}\\ Dual(\\alpha)=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}y^{(i)}y^{(j)}\\langle x^{(i)},x^{(j)}\\rangle $$\n\n$$ s.t.\\ \\ 0\\le\\alpha_i\\le C,\\ \\ i=1,…,m $$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\sum^m_{i=1}\\alpha_iy^{(i)}=0 ​$$\n\n则 KKT 条件可转化为：\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\alpha_i=0\\ \\Rightarrow\\ y^{(i)}(\\omega^Tx^{(i)}+b)\\ge1 ​$$\n\n$$ \\ \\ \\ \\ \\ \\ \\ \\ \\alpha_i=C\\ \\Rightarrow\\ y^{(i)}(\\omega^Tx^{(i)}+b)\\le1 ​$$\n\n$$ 0<\\alpha_i<C\\ \\Rightarrow\\ y^{(i)}(\\omega^Tx^{(i)}+b)=1 $$\n\n\n\n### SMO算法\n\nSMO(sequential minimal optimization)算法提供了一种有效的方式去解决 dual 问题。\n\n当使用函数去优化参数时，可以固定其中一个参数，优化另一个参数，直到达到目标点来完成任务。假设参数$\\alpha_i$满足约束条件，如果固定$\\alpha_2,…,\\alpha_m$仅调整$\\alpha_1$，是否能达到优化目的？\n\n答案是否定的，因为参数$\\alpha_1y^{(1)}=-\\sum^m_{i=2}\\alpha_iy^{(i)}$，但改变一次，可能其它所有参数都会发生改变，就不满足我们的方法条件。\n\n因此，如果要更新参数$\\alpha_i$，必须要至少同时更新两个参数才能保证不违反约束条件，所以 SMO 算法可以简单的分为以下步骤：\n\nRepeat till convergence {\n\n​\t1  选择一堆参数$\\alpha_i,\\alpha_j$去更新\n\n​\t2 重新计算优化函数 dual ，固定剩下的参数\n\n}\n\n为了测试算法的趋势，可以在优化的过程中检查其是否满足 KKT 情况。SMO 算法有效的另一个原因是更新那两个参数的计算十分快。\n\n固定两个参数后，可得：\n\n$$ \\alpha_1y^{(i)}+\\alpha_2y^{(2)}=-\\sum^m_{i=3}\\alpha_iy^{(i)} ​$$\n\n右边参数是固定的，只能调整左边，意味着：\n\n$$  \\alpha_1y^{(i)}+\\alpha_2y^{(2)}=\\zeta $$\n\n$$  \\alpha_1=(\\zeta-\\alpha_2y^{(2)})y^{(1)} $$\n\n$$ Dual(\\alpha_1,\\alpha_2,…,\\alpha_m)=Dual((\\zeta-\\alpha_2y^{(2)})y^{(1)},\\alpha_2,…,\\alpha_m) $$\n\n","tags":["Machine Learning"]},{"title":"Principal Component Analysis","url":"/2019/03/19/Principal-Component-Analysis/","content":"\n> PCA(Principal Component Analysis)，即主成分分析方法，是一种运用广泛的数据降维算法。PCA的主要思想是将N维特征映射到K维空间上，这K维空间中的特征是全新的正交特征，即为主成分，是在原有N维特征空间的基础上重新构造出来的K维特征。PCA的工作就是从原始维度空间中按序找出一组相互正交的坐标轴，坐标轴的选择与数据是密切相关的。首先找出原始数据中方差最大的方向定为第一个坐标轴，其次在第一个坐标轴正交的平面上找到使得数据方差最大的方向定为第二个坐标轴，然后在与之前两个坐标轴都正交的平面上找到方差最大的方向定位第三个坐标轴，以此类推，得到N个坐标轴。其中大部分方差都在前K个坐标轴中，其余几乎为零。所以保留前K个坐标轴，即保留包含大部分方差的维度，忽略其余为度，实现对数据降维的目的。\n\n### 原理\n找到方差最大的K个维度的方法是计算原始数据的**协方差矩阵**，之后得到矩阵的特征值和特征向量，选择特征值最大的，即方差最大的K个特征所对应的特征向量，将这些特征向量组合成一个矩阵，即完成了将原始数据转换到新的维度空间的目的。\n\n样本$X$与样本$Y$的协方差计算方法如下：\n\n$$ Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=\\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y}) $$\n\n对于三维样本数据$X,Y,Z$，计算协方差就转化为计算其协方差矩阵：\n\n$$ Cov(X,Y,Z)=\\begin{bmatrix} Conv(X,X)&Conv(X,Y)&Conv(X,Z)\\\\Conv(Y,X)&Conv(Y,Y)&Conv(Y,Z)\\\\Conv(Z,X)&Conv(Z,Y)&Conv(Z,Z) \\end{bmatrix} $$ \n\n### PCA算法的实现\n\n#### 基于特征值分解协方差矩阵实现PCA算法\n\n**输入**为数据集$X={x_1,x_2,x_3,…,x_n}​$。\n\n1. 将每一个特征减去平均值，即去中心化\n2. 计算协方差矩阵$\\frac{1}{n}XX^T​$\n3. 用**特征值分解法**求协方差矩阵的特征值和特征向量\n4. 对特征值进行排序，选取最大的k个特征值\n5. 将其所对应的k个特征向量作为行向量组合起来形成特征向量矩阵P\n6. 将原始数据转换到新的特征空间中，即$Y=PX​$\n\n#### 基于SVD分解协方差矩阵实现PCA算法\n\n**输入**为数据集$X={x_1,x_2,x_3,…,x_n}$。\n\n1. 将每一个特征减去平均值，即去中心化\n2. 计算协方差矩阵$\\frac{1}{n}XX^T$\n3. 通过**SVD**计算协方差矩阵的特征值和特征向量\n4. 对特征值进行排序，选取最大的k个特征值\n5. 将其所对应的k个特征向量作为行向量组合起来形成特征向量矩阵P\n6. 将原始数据转换到新的特征空间中，即$Y=PX$\n\n### PCA算法的理论\n\n#### 最大方差理论\n\n在信号处理中，认为信号具有较大的方差，而噪声具有较小的方差，信噪比就是信号与噪声的方差比，即越大越好。如果信号在$u_1$上的投影方差较大，在$u_2$上的投影方差较小，那么可以认为$u_2$上的投影是由噪声引起的。则最好的降维结果就是降维之后每一维的样本方差都很大。\n\n#### 主成分个数\n\n$$ \\frac{\\frac{1}{m}\\sum^m_{i=1}\\parallel x^{(i)}-x^{(i)}_{approx}\\parallel^2}{\\frac{1}{m}\\sum^m_{i=1}\\parallel x^{(i)}\\parallel^2}\\le t $$\n\n其中$x_{approx}$表示投影后的位置，选取满足上式条件的最小k值。其中$t$由自己决定，当$t=0.01$则代表PCA算法保留99%的主要信息。\n\n### 代码实现(Java)\n\n```java\nimport Jama.Matrix;\nimport com.sun.source.tree.Tree;\n\nimport java.util.*;\n\npublic class PCA {\n\n    private static final double threshold = 0.95;\n\n    public double[][] meanToZero(double[][] data) {\n        int rows = data.length;\n        int cols = data[0].length;\n        double[] eachRowSum = new double[cols];\n        double[] eachRowAve = new double[cols];\n        for(int i = 0; i < cols; i++) {\n            for (int j = 0; j < rows; j++) {\n                eachRowSum[i] += data[j][i];\n            }\n            eachRowAve[i] = eachRowSum[i] / rows;\n        }\n\n        double[][] newData = new double[rows][cols];\n        for(int i = 0; i < cols; i++) {\n            for(int j = 0; j < rows; j++) {\n                newData[j][i] = data[j][i] - eachRowAve[i];\n            }\n        }\n        return newData;\n    }\n\n    public double[][] getCoveMatrix(double[][] matrix) {\n        int rows = matrix.length;\n        int cols = matrix[0].length;\n        double[][] covMatrix = new double[cols][cols];\n        for(int i = 0; i < cols; i++) {\n            for(int j = 0; j < cols; j++) {\n                double temp = 0;\n                for(int k = 0; k < rows; k++) {\n                    temp += matrix[k][i] * matrix[k][j];\n                }\n                covMatrix[i][j] = temp / rows;\n            }\n        }\n        return covMatrix;\n    }\n\n    public double[][] featureVal(double[][] matrix) {\n        Matrix a = new Matrix(matrix);\n        double[][] res = a.eig().getV().getArray();\n        return res;\n    }\n\n    public Matrix getPrincipalComponent(double[][] preArray, double[][] featureVal, double[][] featureVec) {\n        Matrix a = new Matrix(featureVec);\n        double[][] featureVecT = a.transpose().getArray();\n        Map<Integer, double[]> principalMap = new HashMap<Integer, double[]>();\n        TreeMap<Double, double[]> featureMap = new TreeMap<Double, double[]>(Collections.reverseOrder());\n        double feaValSum = 0;\n        int index = 0, n = featureVal.length;\n        double[] featureValArray = new double[n];\n        for(int i = 0; i < n; i++) {\n            for(int j = 0; j < n; j++) {\n                if(i == j) {\n                    featureValArray[index] = featureVal[i][j];\n                }\n            }\n            index++;\n        }\n        for(int i = 0; i < featureVecT.length; i++) {\n            double[] val = new double[featureVecT[0].length];\n            val = featureVecT[i];\n            featureMap.put(featureValArray[i], val);\n        }\n\n        for(int i = 0; i < n; i++) {\n            feaValSum += featureValArray[i];\n        }\n\n        double tmp = 0;\n        int principalComponentNum = 0;\n        List<Double> pcFeaVal = new ArrayList<Double>();\n        for(double key : featureMap.keySet()) {\n            if(tmp / feaValSum <= threshold) {\n                tmp += key;\n                pcFeaVal.add(key);\n                principalComponentNum++;\n            }\n        }\n        System.out.println(\"\\n\" + \"特征阈值：\" + threshold);\n        System.out.println(\"得到主成分个数：\" + principalComponentNum + \"\\n\");\n\n        for(int i = 0; i < pcFeaVal.size(); i++) {\n            if(featureMap.containsKey(pcFeaVal.get(i))) {\n                principalMap.put(i, featureMap.get(pcFeaVal.get(i)));\n            }\n        }\n\n        double[][] principalArray = new double[principalMap.size()][];\n        Iterator<Map.Entry<Integer, double[]>> it = principalMap.entrySet().iterator();\n        for(int i = 0; it.hasNext(); i++) {\n            principalArray[i] = it.next().getValue();\n        }\n\n        Matrix principalMatrix = new Matrix(principalArray);\n        return  principalMatrix;\n    }\n\n    public Matrix getRes(double[][] pre, Matrix matrix) {\n        Matrix preMatrix = new Matrix(pre);\n        Matrix res = preMatrix.times(matrix.transpose());\n        return res;\n    }\n\n    public static void main(String[] args) {\n\n        PCA pca = new PCA();\n        //获得样本集\n        double[][] data = new double[2][4];\n        data[0][0] = 5.1;\n        data[0][1] = 3.5;\n        data[0][2] = 1.4;\n        data[0][3] = 0.2;\n        data[1][0] = 4.9;\n        data[1][1] = 3.0;\n        data[1][2] = 1.4;\n        data[1][3] = 0.2;\n        System.out.println(\"--------------------------------------------\");\n        System.out.println(\"原数据: \");\n        for(int i = 0; i < data.length; i++) {\n            for(int j = 0; j < data[i].length; j++) {\n                System.out.print(data[i][j]);\n                System.out.print(\" \");\n            }\n            System.out.print(\"\\n\");\n        }\n        System.out.println(\"--------------------------------------------\");\n        //均值为零矩阵\n        double[][] averageArray = pca.meanToZero(data);\n\n        //协方差矩阵\n        double[][] varMatrix = pca.getCoveMatrix(averageArray);\n\n        //特征值矩阵\n        double[][] eigenvalueMatrix = pca.featureVal(varMatrix);\n\n        //特征向量矩阵\n        double[][] eigenVectorMatrix = pca.featureVal(varMatrix);\n\n        //主成分矩阵\n        Matrix principalMatrix = pca.getPrincipalComponent(data, eigenvalueMatrix, eigenVectorMatrix);\n\n        //降维后矩阵\n        Matrix resultMatrix = pca.getRes(data, principalMatrix);\n\n        int c = resultMatrix.getColumnDimension(); //列数\n        int r = resultMatrix.getRowDimension();//行数\n        System.out.println(resultMatrix.getRowDimension() + \",\" + resultMatrix.getColumnDimension());\n\n    }\n}\n```\n\n","tags":["Machine Learning"]},{"title":"Multi Attention Module for Visual Tracking","url":"/2019/01/17/Multi-Attention-Module-for-Visual-Tracking/","content":"\n论文链接：[Boyu Chen, Peixia Li, Chong Sun, Dong Wang, Gang Yang, Huchuan Lu. Multi attention module for visual tracking[]//Pattern Recognition, 2019. 87: 80-93.](https://www.sciencedirect.com/science/article/pii/S0031320318303509?via%3Dihub)\n\n### 主要内容\n\n这篇论文主要提出了使用四种 attention 进行融合来提升目标跟踪算法的性能和速率，提出一种融合了这四种注意力机制的网络和一种降低跟踪漂移的检测策略。\n\n- Layer-wise attention 不同层的深度特征可能适合不同的场景，利用离线方法训练网络在跟踪过程中在线选择适合的特征；\n- Temporal attention 应用 LSTM 捕捉目标的历史信息，从而提供可靠的信息供算法对当前帧进行分析，探索跟踪任务的时间连续性；\n- Spatial attention 提取目标的空间信息，从而对当前帧的图像进行有针对性的特征提取，降低周围背景噪声对算法的影响；\n- Channel-wise attention 卷积特征中不同通道对图像中不同区域产生不同的影响，有针对性的提取特定通道的特征可以降低背景影响，提升网络对目标区域的关注度。\n\n**Layer-wise attention**\n\n深度网络中高层特征更多的表达目标类别性的语义信息，对目标的外观变化具有很强的鲁棒性；低层特征更多的保存目标的空间细节信息，但对目标的形态变化很敏感。之前的工作只是对这些特征进行简单的融合，缺少有效的注意力机制让有用的层发挥作用，耗费了计算资源。\n\n**Temporal attention**\n\n现如今目标跟踪算法鲜有利用视频的时空信息，但视频却有着很强的时空一致性特征，目标在相邻的帧间很少发生大的形变和位移，利用时空信息就可以有效压制错误的正样本。而 RNN 网络在提取相关联序列化的数据很有效，如何有效的将时空信息加入跟踪算法里很重要。\n\n**Spatial attention**\n\n空间信息提供了单幅图像中的内部关系，跟踪任务通过前几帧预测的目标位置可以有效的决定当前帧中大概哪些区域是前景，哪些区域是背景，可以对前景部分设置较高的权重值从而通过 ROI 池化层确定感兴趣的区域。\n\n**Channel-wise attention**\n\n利用大规模数据集预训练好的深度网络在判别物体性质上很有用，它将提取的所有频道的信息都一视同仁，这种方法并不适合目标跟踪任务。不同频道提取图像中不同的语义信息，有些频道特征对于物体定位很有用，有些对于定位任务却如同噪声显得非常冗余，从而导致了跟踪漂移现象。选择合适频道的特征可以提升目标区域的关注度，同时压制背景的响应。\n\n### 方法内容\n\n#### 多种注意力机制模块\n\n**时间注意力模块**\n\n将连续帧间的视觉注意力问题视为一个序列化问题，采用 LSTM 单元添加时间一致性信息。在第 t 个时间点上，LSTM 被定义为：\n\n$$ \\begin{pmatrix}{f_{t}}\\\\{i_{t}}\\\\{o_{t}}\\\\{g_{t}}\\end{pmatrix}=\\sigma(W_{hh}h_{t-1}+W_{ih}x_{t}+b)  ​$$\n\n$$ c_{t}=f_t \\odot c_{t-1} +i_t \\odot g_t​$$\n\n$$ h_t=o_t \\odot tanh(c_t) ​$$\n\n$x_t$为输入的特征；$h_t$是隐藏状态；$c_t$是细胞状态；$W_{hh}$是隐藏层和隐藏层间的核权重；$W_{ih}$是输入层和隐藏层间的核权重；$f_t,i_t,o_t,g_t$分别是忘记门、输入门、输出门和内容门；$\\sigma$是前三个门使用的$sigmoid$激活函数；$tanh$是内容门使用的激活函数。\n\n将$h_t$作为时间注意力模块的输出信息，此信息后续被用于空间注意力和频道注意力模块中。\n\n<center>{% asset_img LSTM.png 500 250 时间注意力模块 %}</center>\n\n**空间注意力模块**\n\n给定图像特征$V\\in\\mathbb{R}^{W\\times H\\times C}​$和 LSTM 输出$h_t​$，首先将图像特征的二维特征转化为一维特征，宽和高相分离，即$V_s=[v_1,v_2,...,v_n]​$这$W\\times H​$个特征向量，$v_{i}\\in\\mathbb{R}^C​$。将此特征向量经过一个单层的神经网络并使用$softmax​$激活函数来生成$W\\times H​$这片区域的注意力权重：\n\n$$ A_a=tanh((W_1V_S+b_1)\\oplus W_2h_t) $$\n\n$$ A_s=softmax(W_3A_a+b_3) ​$$\n\n$W_1\\in\\mathbb{R}^{n\\times C}, W_2\\in\\mathbb{R}^{n\\times d}, W_3\\in\\mathbb{R}^n​$是为了平衡图像特征和隐藏状态的权重参数，$b_1\\in\\mathbb{R}^n, b_3\\in\\mathbb{R}^1​$是模型的偏置，$\\oplus​$代表了一个矩阵和一个向量的$broadcast​$加法操作。\n\n**频道注意力模块**\n\n通过和空间注意力模块相似的步骤来选择适合当前跟踪任务的卷积核滤波器，从而选择适合的频道特征。给定图像特征$V\\in\\mathbb{R}^{W\\times H\\times C}$和 LSTM 输出$h_t$，首先将图像特征做全局平均池化操作得到频道特征$v'$：\n\n$$ V_C=[v'_1,v'_2,...,v'_c], v'\\in\\mathbb{R}^C $$\n\n$v'_i$是将 2D 特征作全局平均池化输出的第 i 个频道的特征，在此之后添加一个单层的神经网络并使用$softmax$激活函数来生成频道注意力：\n\n$$ A_b=tanh((W'_1\\otimes V_C+b'_1)\\oplus W'_2h_{t-1}) ​$$\n\n$$ A_c=softmax(W'_3A_b+b'_3) $$\n\n$W'_1\\in\\mathbb{R}^{C\\times C}, W'_2\\in\\mathbb{R}^{C\\times d}, W'_3\\in\\mathbb{R}^C$是为了平衡图像特征和隐藏状态的权重参数，$b'_1\\in\\mathbb{R}^C, b'_3\\in\\mathbb{R}^1$是模型的偏置，$\\otimes$代表了向量的外积操作。\n\n**网络层注意力模块**\n\n给定空间权重$A_s$，频道权重$A_c$和图像特征$V$，则通过对空间权重和特征做点乘操作得到空间特征$F_s$，通过将频道权重单独应用于每个频道得到频道特征$F_c$。之后将这些特征放入全连接层和$ReLU$激活单元。最后融合两种类型的特征并利用一个全连接层和$softmax$函数组成的分类器产生分数。在本文中，只关注 Conv5-3 和 Conv4-3 这两种的卷积特征。\n\n#### 跟踪模块\n\n对于每个图像的 Conv4-3 和 Conv5-3 特征，利用一个卷积层和三个全连接层输出目标的类别信息。一个卷积层的目的主要是通过$1\\times 1$的卷积核产生256个频道特征用于降维。其中两个全连接层有512个输出单元并接上$ReLUs$激活函数。最后一个全连接层输出两个响应值，分别代表了前景和背景的可能性分数。\n\n#### 将多种注意力模块与跟踪模块相结合\n\n**候选区域的特征提取**\n\n将跟踪任务转化为检测-跟踪框架，给定第$t​$帧的视频图像$I^t​$和上一帧的目标位置$X^{t-1}​$，根据高斯分布模型$p(X^t|X^{t-1})=\\mathcal{N}(X^t;X^{t-1},\\sum)​$以$X^{t-1}​$为中心，方差为$\\sum​$生成目标候选集${X^t_i}​$。\n\n特征提取阶段直接先提取整幅图像的特征，而不是独自提取不同候选集的特征，减少了计算量。之后利用$RoI$池化层作用于此特征图，将每个候选集的特征图聚集成响应值投射在一个$7\\times 7\\times 512$大小的窗口上固定特征表征。在这个过程中，仅用了一次前向计算就得到了所有候选目标的特征表示。\n\n**注意力特征图规则**\n\n为了减少候选数量，使用一个 attention map guidance 方法：\n\n$$ F_a=\\frac{1}{C}\\sum^C f_c(A_c,f_s(A_s,V)) $$\n\n$F_a$即为 attention map。\n\n之后，所有的候选目标通过注意力分数的总和被降序排序，仅保留 K 个候选集。选择具有较高分数的网络层特征，从全局特征图中将候选集的特征裁剪出来并将它们进行评估。\n\n**目标定位**\n将上述的候选集特征分别送入两个子网络中，两个网络拥有相同的结构但参数不同。最后得到候选集的可能性分数，选出最高的一个作为最终预测的目标。\n\n**初始化和更新**\n\n给定第一帧的初始化目标位置$X^1​$，生成正样本集$\\mathcal{X}_+​$和负样本集$\\mathcal{X}_-​$。上述的两个子网络通过最小化如下的 SGD 函数进行初始化：\n\n$$ arg\\min_{\\theta}-\\sum_{X\\in \\mathcal{X}_+}p_+(X|f;\\theta)-\\sum_{X\\in\\mathcal{X_-}}  p_-(X|f;\\theta)​$$\n\n为了使算法适应目标的外观变化，在跟踪模块中每一帧都基于上述初始化的方法更新参数。\n\n<center>{% asset_img feature.png 500 500 搭载注意力模块的特征提取部分 %}</center>\n\n#### 合并检测的结果\n\n采用 Faster-RCNN 的检测器，预训练包含了20种类别。跟踪的目标可能不在这些类别之内，首先计算检测的目标窗口和标定目标的覆盖率，如果低于阈值则在跟踪中不考虑检测结果，否则通过三种策略来考虑检测结果。\n\n**精炼跟踪结果**\n\n通过检测得到的结果来精炼跟踪所得到的结果，计算跟踪结果和所有检测结果窗的覆盖率，如果高于阈值则选择具有最高分数的检测结果窗作为最终预测的目标位置。\n\n**严重负样本处理**\n在每一帧中，检测器都提供了一系列潜在的目标，这些目标可能会严重干扰跟踪器。所以将这些目标视为严重负样本，将它们加入训练样本集，更新跟踪算法参数。\n\n**跟踪重置**\n\n许多情况会导致跟踪漂移，大部分时候是由于运动模型而导致的。当发生此情况时，通过添加所有同类别的检测窗目标来扩充目标候选样本，将这些检测得到的同类别物体作为目标。\n\n### 实验结果\n\n算法的具体参数设计请参考论文第4节。\n\n<center>{% asset_img otb2013.png 600 300 OTB2013结果图 %}</center>\n\n<center>{% asset_img otb100.png 600 300 OTB100结果图 %}</center>\n\n<center>{% asset_img tc128.png 600 300 TC128结果图 %}</center>\n\n<center>{% asset_img ablation.png 600 300 应用不同模块在OTB2013上的结果图 %}</center>\n\n### 改进空间\n\n1. 运行速度有待提升；\n2. 提取的特征固定为$7\\times 7$，这个尺寸对于小目标来说不合适，会丢失很多信息；\n3. 在多种跟踪数据集上离线训练算法，并联合端到端的模型。\n","tags":["Paper Review"]},{"title":"Git操作方法","url":"/2018/12/11/Git操作方法/","content":"\n### Git工作流程\n\nGit有4个重要名词：\n\n- Workspace 工作区\n- Index / Stage 暂存区\n- Repository 本地仓库\n- Remote 远程仓库\n\n**工作区**\n\n拷贝远程仓库的一个分支，并在此分支上进行开发，是最新的。开发工作就是对工作区进行的操作。\n\n**暂存区**\n\n通过`git add`命令添加文件的相关信息，如文件名、大小等，并不保存文件实体，只是通过序号指向每个文件，保存在`.git`目录下的`index`文件里，任何的开发只有进入此文件内才开始被版本控制。可以使用`git status`查看暂存区的状态。\n\n**本地仓库**\n\n保存每个分支提交过的各个版本，包含旧版本。可以使用`git commit`命令同步`index`里所保存的文件信息到本地仓库。\n\n**远程仓库**\n\n可以使用`git push`命令将本地仓库与远程仓库进行同步操作，远程仓库可以被多个处于协同关系的本地仓库修改。\n\n<center>{% asset_img relations.png 350 300 四个内容之间的关系 %}<center>\n\n\n\n### Git命令\n\n`git clone <url>` 克隆远程仓库\n\n`git init` 初始化本地仓库\n\n`git status` 查看暂存区状态\n\n`git diff` 查看变更内容\n\n`git add .` 将所有改动过的文件进行跟踪（受版本控制）\n\n`git add <file>` 将制定文件进行跟踪\n\n`git mv <old> <new>` 将文件进行更名\n\n`git rm <file>` 删除文件\n\n`git rm --cached <file>` 将文件停止跟踪但不删除\n\n`git commit -m \"commit\"` 提交所有更新后的文件，含备注\n\n`git commit --amend` 修改最后一次提交\n\n`git log` 查看提交历史\n\n`git log -p <file>` 查看指定文件的提交历史\n\n`git blame <file>` 以列表形式查看指定文件的提交历史\n\n`git reset --hard HEAD` 撤销工作目录中所有未提交文件的修改内容\n\n`git checkout HEAD <file>` 撤销指定的未提交文件的修改内容\n\n`git revert <commit>` 撤销指定的提交\n\n`git branch` 显示所有本地分支\n\n`git checkout <branch / tag>` 切换到指定分支或标签\n\n`git branch <new branch>` 创建新分支\n\n`git branch -d <branch>` 删除本地分支\n\n`git tag` 列出所有本地标签\n\n`git tag <tag name>` 基于最新提交创建标签\n\n`git tag -d <tag name>` 删除指定标签\n\n`git remote -v` 查看远程仓库信息\n\n`git remote show <remote>` 查看指定远程仓库信息\n\n`git remote add <remote> <url>` 添加远程仓库\n\n`git fetch <remote>` 从远程仓库获取代码\n\n`git pull <remote> <branch>` 下载代码并快速合并\n\n`git push <remote> <branch>` 上传代码并快速合并\n\n`git push <remote> :<branch / tag name`> 删除远程分支或标签\n\n`git push --tags` 上传所有标签\n\n其中：`HEAD`指向当前分支的最新提交点，`add`实现将工作区修改的内容提交的暂存区，`commit`实现将暂存区的内容提交到本地仓库并更改最新提交点，`rebase`和`merge`都是实现合并操作，后者会生成一个新节点与旧内容分开，而前者不会，只是将两个分支融合成一个线性的分支，`revert`和`reset`都是变更当前指向位置，前者是用一个新提交来消除一个旧提交，而后者是直接删除指定提交。\n\n\n\n### 上传本地仓库到GitHub\n\n如何将自己的本地代码上传到GitHub仓库呢？\n\n1. 在本地创建一个目录，执行`git init`命令，之后会在此目录下创建一个`.git`文件夹；\n\n2. 将所要上传的所有文件放入此文件夹中，并执行`git add .`命令将所有文件添加到待上传的列表中，`.`表示当前目录中所有文件，也可以选部分文件；\n3. 将待上传的列表文件执行`git commit -m \"comment\"`进行确认操作，其中`comment`是注释语句，可以说明此次上传的意义；\n4. 在GitHub的Repository中找到当前仓库的SSH地址`git@github.com:username/repo_name.git`，执行`git remote add origin SSH_address`命令将本地的仓库关联到GitHub的仓库上；\n5. 执行`git push -u origin master`命令将代码上传到GitHub上。\n\n若之前在此目录中已经关联过GitHub，则不需要执行第1、4步。\n","tags":["Practical Method"]},{"title":"通信网络总结","url":"/2018/12/06/通信网络总结/","content":"\n### OSI参考模型\n\n**物理层**\n\n负责0、1比特流与电压的高低、光的闪灭之间的互换。\n\n**数据链路层**\n\n负责物理层面上互连的、节点之间的通信传输。将0、1序列划分为一个一个的数据帧传送给对方。每一个数据帧都包含了“报文首部”，即发送端地址、接收端地址、分组序号等。\n\n**网络层**\n\n将数据传输到目标地址，主要负责寻址和路由选择。\n\n**传输层**\n\n管理两个节点间的数据传输，只在通信双方节点上进行处理，而无需在路由器上处理。\n\n**会话层**\n\n负责通信的管理，建立和断开通信连接，以及数据的分割等。\n\n**表示层**\n\n负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能够处理的格式。具体来说，就是将设备固有的数据格式转换为网络标准传输格式。\n\n**应用层**\n负责每个应用的协议，为应用程序提供服务并规定应用程序中通信相关的细节。包括文件传输、电子邮件、远程登录等各种协议。\n\n### TCP/IP分层模型\n\n**硬件**\n\n负责数据传输，相当于物理层的设备。\n\n**网络接口层**\n\n利用以太网中的数据链路层进行通信，属于接口层，又称**驱动程序**。\n\n**互联网层**\n\n使用IP协议，基于IP地址转发分包数据，相当于网络层，由操作系统提供。当数据包在发送途中发生异常时，需要给发送端一个异常通知，即为ICMP，它同时具有诊断网络健康状况的作用。之后利用ARP协议从分组数据包的IP地址解析出MAC物理地址。\n\n**传输层**\n作用是分清是计算机中哪些程序与哪些程序在进行通信，识别端口号，由操作系统提供。TCP是面向右链接的传输层协议，保证通信可达。UDP是面向无连接的传输层协议，不关注接收端是否收到数据。\n\n**应用层**\n\n将OSI中的会话层、表示层和应用层的功能都集中起来，由应用程序实现。\n\n- 浏览器与服务器端之间的通信协议是HTTP，传输数据格式是HTML，其中HTTP属于应用层协议，HTML属于表示层协议。\n- 电子邮件协议是SMTP，MIME是其扩展，可以发送声音、图像等信息，属于表示层协议。\n- 文件传输协议是FTP，在此过程中建立两个TCP连接，分别发出控制连接和数据连接。\n- 远程登录协议是SSH。\n- 网路管理协议是SNMP，属于应用层协议。\n\n整体信息：\n\n接收端MAC地址+发送端MAC地址+以太网类型+发送端IP地址+接收端IP地址+协议类型+源端口号+目标端口号+数据+循环冗余校验\n\n### IP协议（网络层）\n\n网络层的主要作用是实现两个终端点对点的通信。\n\nIP的主要作用是在复杂的网络环境中将数据包发送给最终的目标地址。\n\n网络层与数据链路层的区别在于网络层是行程表，告诉了车票在哪个限定的区间内进行移动，而数据链路层就是车票，标有起始位置和终止位置，并作为移动的依据。即数据链路层只负责某一区间内的通信传输，网络层负责点对点通信，也就是负责限定在哪个区间。\n\nIP属于面向无连接型，即使对端主机不存在，数据包还是会发送出去。IP只负责将数据发送出去，TCP负责保证数据的可靠性。\n\nIPv4地址由32位二进制正整数来表示，分为每八位一组，每组以`.`隔开，将每组二进制数转换为十进制。\n\nIP地址由网络地址和主机地址两部分组成，以子网掩码（对应网络地址的位置全为`1`，对应主机地址的位置全为`0`）区分（如今）。\n\nIP地址分为四个级别（20世纪90年代），根据地址中从第一位到第四位的比特列对网络地址和主机地址进行区分，同时主机地址不能全为0（地址不可获知情况）或者全为1（广播情况）：\n\n1. **A类地址** 以`0`开头 第1位到第8位是网络地址 0.0.0.0～127.0.0.0 主机容纳上限为16，777，214个\n2. **B类地址** 以`10`开头 第1位到第16位是网络地址 128.0.0.0～191.255.0.0 主机容纳上限为65，534个\n3. **C类地址** 以`110`开头 第1位到第24位是网络地址 192.0.0.0～223.255.255.0 主机容纳上限为254个\n4. **D类地址** 以`1110`开头 第1位到第32位是网络地址 224.0.0.0～239.255.255.255 没有主机地址，常用于多播\n\nCIDR：在地址后面加上`/数字`代表了网络地址所占的位数，可以以任意长度分割两种地址，也可以将两个地址合并为一个网络。\n\n私有地址和公有地址：在路由器或者服务器上设置全局IP地址，即公有地址，之后在每个终端设置私有地址。公有地址不能重复，而私有地址可以在互联网上重复，不能在本地重复。这种技术是NAT技术，将IPv4和NAT技术结合解决地址缺少的问题。\n\nIPv6地址由128位二进制正整数来表示，前64位为网络地址，后64位为主机地址，以每16比特位一组，用冒号分隔，如果出现连续的零可省略，用两个冒号隔开，只允许出现一次两个连续的冒号，特点如下：\n\n1. IP地址扩大，路由控制表聚合\n2. 性能提升\n3. 支持即插即用功能\n4. 采用认证与加密功能\n5. 多播、Mobile IP成为扩展功能\n\nDNS：管理主机名和IP地址之间对应关系的系统。\n\nARP：通过发送ARP请求包，包含发送目标的IP地址，ARP会被这同一链路上所有的主机和路由器进行解析，如果包中目标地址与自己的IP地址一致，则这个节点将自己的MAC地址塞入ARP响应包冰返回。即**可以通过ARP从IP地址获得MAC地址**。\n\nICMP：确认网络是否正常工作，以及遇到异常情况时进行问题诊断。`ping`命令就是基于此功能的，功能如下：\n\n1. 确认IP包是否成功送达目标地址\n2. 通知发送过程中IP包被废弃的具体原因，通知消息使用IP进行发送\n3. 改善网络设置\n\nDHCP：实现自动设置IP地址、统一管理IP地址分配（让即插即用变成了可能）。一般家庭使用宽带路由器充当此角色。\n\n从DHCP服务器中获取IP地址的流程如下：\n\n1. 管理员在DHCP服务器上设置可分配的IP地址、子网掩码以及默认路由；\n2. DHCP服务器通知可以使用的网络设置；\n3. 通知想要使用在2中通知的设置；\n4. 通知允许3的设置。\n\n之后就可以进行TCP/IP通信，当不需要IP时，可发送DHCP接触包。\n\nNAT：用于在本地网络中使用私有地址，在连接互联网时转而使用全局IP地址的技术，实现用一个全局IP地址与多个主机的通信。\n\n### TCP/UDP（传输层）\n\nTCP是面向连接的、可靠的流协议。\n\nUDP是不具有可靠性的数据报协议。\n\n通过5个信息来识别一个通信：\n\n- 源IP地址\n- 目标IP地址\n- 协议号\n- 源端口号\n- 目标端口号\n\nTCP通过检验和、序列号（发送数据的位置，即发送到哪了，接下来该发送什么）、确认应答、重发控制、连接管理、窗口控制等机制实现可靠性传输。\n\nTCP以段为单位发送数据，即最大消息长度（MSS），由两端主机之间计算得出。\n\n**确认应答**\n\n当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。\n\n**重发控制**\n\n重发超时：每次发包时都会计算往返时间及其偏差，比这个总和稍大一点的值即为重发超时。（0.5秒的整数倍，6秒左右）\n\n**连接管理**\n\n数据通信前，通过TCP首部发送一个SYN包作为建立连接的请求等待确认应答。通信结束时会发送一个FIN包作为断开连接的请求。\n\n一个连接的建立与断开，正常过程至少需要来回发送7个包才能完成。\n\n**三次握手**\n\nA->B SYN请求连接\n\nB->A ACK针对SYN的确认应答，并SYN请求连接\n\nA->B ACK对SYN的确认应答\n\n通信连接完成……\n\n**四次挥手**\n\nA->B FIN请求断开\n\nB->A ACK针对FIN的确认应答\n\nB->A FIN请求断开\n\nA->B ACK针对FIN的确认应答\n\n**窗口控制**\n在通信双方往返时间较长的情况下，控制网络性能。确认应答不再以段为单位，而是更大的单位。\n\n窗口大小指无需等待确认应答而可以继续发送数据的最大值。\n\n再没收到确认应答之前，所有数据发送的同时，会进入缓冲区，如果失败则重新发送，如果成功则将缓冲区中确认收到的信息清除。\n\nUDP首部格式：源端口号、目标端口号、包长度、校验和。\n\n当校验和不匹配时，所有接收结果都被抛弃。\n\nTCP首部格式：源端口号、目标端口号、序列号、确认应答号、数据偏移、保留、控制位、窗口大小、校验和、紧急指针、选项、填充。\n\n","tags":["Method Summary"]},{"title":"Logistic Regression","url":"/2018/12/06/Logistic-Regression/","content":"\n逻辑回归是一种**判别式**模型，与线性回归拟合数值有一定区别。逻辑回归假设因变量服从伯努利分布，而线性回归假设因变量服从高斯分布。通过Sigmoid激活函数引入非线性因素。逻辑回归的目的是**分类**，多用于解决二分类问题，它与多重线性回归分析类似。\n\n### 定义\n逻辑回归定义为：\n- 假设函数\n  $$ \\hat{y} = sigmoid(\\omega^T x + b) = P(y=1|x;\\omega) $$\n\n- 决策函数\n  $$ y = 1, if P(y=1|x) > 0.5 $$\n\n\n### 最佳拟合参数\n\n以上定义就是逻辑回归的主要思想，那么该如何求最佳参数$ \\omega $使得函数充分拟合数据呢？这里使用最优化算法中的梯度上升方法求解，更新参数的公式如下：\n\n$$ \\omega_j := \\omega_j - \\alpha \\frac{\\partial}{\\partial\\omega_j}J(\\omega) = \\omega_j - \\alpha \\sum_{i=1}^m (h_\\omega (x^{(i)}) - y^{(i)})x^{(i)}_j $$\n\n其中：$ \\alpha $是步长，函数$ h $就为上面的带参数的假设函数。\n\n更新的过程就是梯度变化的过程，梯度就是函数变化最快的方向。首先初始化参数$ \\omega $为单列的1矩阵，在算法中设置一个最大迭代次数，在这个次数内每次计算梯度，并沿此方向更新参数，直到参数达到最优活着次数达到最大。\n\n代码分析如下：\n\n```python\ndef gradAscent(data, label, alpha, maxEpoches, minError):\n    '''\n    Gradient Ascent\n    :param data: m*n \n    :param label: m*1 \n    :param alpha: parameter\n    :param maxEpoches: the number of epoch\n    :param minError: the minimum of error\n    :return: optimized parameters\n    '''\n    m, n = np.shape(data)\n    weigh = np.ones((n,1))\n    for i in range(maxEpoches):\n        h = sigmoid(data * weigh)\n        error = label - h # size -> m*1\n        if error < minError: # smaller than minError\n        \tbreak\n        # w = w + a * x^T * error\n        weigh = weigh + alpha * data.transpose() * error\n    return weigh\n```\n\n\n\n### 均方误差\n\n度量模型性能的一种方法是计算**均方误差**（MSE），公式表示为：\n$$ MSE = \\frac{1}{2m} \\sum_{i}^m (\\hat{y}^{(pred)}_i - y^{(label)}_i )^2 $$\n\n\n\n### 激活函数\nSigmoid函数定义为：\n\n$$ g(z) = \\frac{1}{1+e^{-z}} $$\n\n\n### 决策边界\n决策边界因数据的不同分为线性和非线性，由$ \\omega^T x = 0 $定义。\n\n\n\n### 代价函数\n代价函数$ J(\\omega) $是一个标量，可以用来评价模型的性能，数值越小代表模型和参数越符合训练样本。所以，训练的目的就是最小化代价函数$ J(\\omega) $，而训练的过程使用的方法就是梯度下降（Gradient Descent）。在逻辑回归中最常用的代价函数是**交叉熵**，定义如下：\n$$ J(\\omega) = \n\\begin{cases}\n-\\log(h_\\omega (x))& \\text{y=1}\\\\\n-\\log(1-h_\\omega (x))& \\text{y=0}\n\\end{cases} $$\n其中，$ h_\\omega (x) = \\frac{1}{1+e^{(-\\omega^T x)}} $\n$$ J(\\omega) = -\\frac{1}{m} [\\sum_{i}^m (y^{(i)} \\log{h_\\omega (x^{(i)})} + (1-y^{(i)})\\log({1-h_\\omega (x^{(i)})})] ​$$\n\n\n\n### 梯度下降\n\n梯度是指代价函数$ J(\\omega) $对每个参数的偏导数，而偏导数的正负决定了学习过程中参数的下降方向，学习率$ \\alpha $决定了每次变化的步长。之后利用偏导数和学习率进行梯度下降操作，更新其参数。假设代价函数中的参数为$ \\theta $，则更新参数的过程如下：\n$$ \\theta_j = \\theta_j - \\alpha(\\frac{\\partial}{\\partial\\theta_j})J(\\theta) = \\theta_j - \\alpha(\\frac{1}{m}\\sum_{i=1}^m (h_\\theta (x^{(i)}) - y^{(i)})x^{(i)}_j $$\n\n\n","tags":["Machine Learning"]},{"title":"Decision Tree","url":"/2018/10/31/Decision-Tree/","content":"\n> 决策树是运用于分类任务的一种树形结构，其中每个内部节点代表某一属性特征，叶节点代表某个类别。决策树的决策过程从根节点开始，将数据与特征节点进行比较，并根据结果选择下一分支，直到叶节点作为最终的分类结果。\n\n<center>{% asset_img 决策树.png 300 250 决策树示例图 %}</center>\n\n### 决策树算法过程\n\n1. 特征节点选择：从训练数据的特征中选择一个特征作为当前节点的分裂依据；\n2. 决策树生成：根据所有特征评估标准，从上至下递归生成子节点，直到数据不可分为止；\n3. 剪枝：应对过拟合问题，通过剪枝来缩小树的结构和规模。\n\n### ID3算法\n\n#### 算法介绍\n\nID3算法的目的是决策树在分裂的时候，能够使得分裂之后的两个分支最终所能代表不同的类别，即分类之后节点的\"纯度\"越来越高。为了衡量分裂之后节点的\"纯度\"，使用**信息熵**这个指标，选取使得信息熵增益最大的节点特征进行分裂。\n\n样本集合$D$中第$k$类样本所占比例为$p_k​$，则信息熵的定义如下：\n\n$$ I(D)=-\\sum^{|y|}_{k=1}p_k\\log_2^{p_k} $$\n\n节点属性$x$有$N$个可能的取值，即${x_1,x_2,x_3,…,x_n}$，而在样本集合$D$中，属性$x$中取值为$x_n$的样本集合记为$D_n$，则利用节点属性$x$对样本集合$D$进行划分所能得到的信息增益为：\n\n$$ G(D,a)=I(D)-\\sum_{n=1}^{N}\\frac{|D_n|}{|D|}I(D_n) $$\n\n**信息增益**即表示当知道节点属性$x$的信息时，使得样本集合不确定性减少的程度。所以在ID3算法中，决策树中每个节点是否进行分裂取决于分裂之后的信息增益是否最大化。\n\n#### 算法缺陷\n\n当某种类别可取值数目较多时，信息增益属性能够有效衡量分裂的好坏。但是当某种类别只取一种值时，条件熵为零，则信息增益就无法取得好的效果。\n\n### C4.5算法\n\n#### 算法介绍\n\nC4.5算法利用**信息增益率**这个指标来衡量节点分裂的好坏，它是将信息增益和属性的固有值综合考虑而产生的指标。\n\n属性$x$的固有值能够反映出此节点属性最终能够分成的类别数目，当选取$x$作为分裂节点，最终通过此节点所得到的类别数目越多，此节点的固有值就越大，公式如下：\n\n$$ IV(x)=-\\sum^N_{n=1}\\frac{|D_n|}{|D|}\\log_2^{\\frac{|D_n|}{|D|}} $$\n\n为了改善ID3算法，使得当此节点进行分裂所得到的类别数目越多时，即表明此节点的分裂\"纯度”越低，则信息增益率可写为：\n\n$$ G_{ratio}(D,x)=\\frac{G(D,x)}{IV(x)} $$\n\n而信息增益率其实是对可取类别数目较少的节点特征有所偏爱，即这个节点所得到的类别数目越少，就在此节点进行分裂，容易导致边缘化和极端化。所以C4.5算法不直接采用信息增益率这个判别指标，而是首先选取节点属性的信息增益率高于平均水平的那些作为候选节点，之后从这些候选节点中选择信息增益最高的那个节点作为当前分裂节点。\n\n","tags":["Machine Learning"]},{"title":"排序算法总结","url":"/2018/10/31/排序算法总结/","content":"\n本文主要总结排序算法。\n\n| 排序算法 | 平均时间复杂度 | 最坏复杂度 | 空间复杂度 | 稳定性 |\n| ------ | ------ | ------ | ------ | ------ |\n| 冒泡排序 | $ O(N^2) $ | $ O(N^2) $ | $ O(1) $ | 稳定 |\n| 选择排序 | $ O(N^2) $ | $ O(N^2) $ | $ O(1) $ | 不稳定 |\n| 插入排序 | $ O(N^2) $ | $ O(N^2) $ | $ O(1) $ | 稳定 |\n| 快速排序 | $ O(N\\log(N)) $ | $ O(N^2) $ | $ O(1) $ | 不稳定 |\n| 归并排序 | $ O(N\\log(N)) $ | $ O(N\\log(N)) $ | $ O(1) $ | 稳定 |\n| 堆排序 | $ O(N\\log(N)) $ | $ O(N\\log(N)) $ | $ O(1) $ | 不稳定 |\n| 希尔排序 | $ O(N\\log(N)) $ | $ O(N\\log(N)) $ | $ O(1) $ | 不稳定 |\n\n### 冒泡排序\n基于**比较**的排序算法，优点是**稳定**、实现简单、**N较少时性能良好**。\n#### 原理\n遍历整个数组，**相邻的两个数据进行比较**，小的放在前面，大的放在后面，如此类推，直到排序完成。\n\n- $ O(1) $的额外空间\n- $ O(N^2) $次比较\n- $ O(N^2) $次交换\n- 自适应性\n\n#### 代码\n{% codeblock lang:c %}\n\tvoid bubble_sort(int a[], int len)\n\t{\n        \tfor (int i = 0; i < len-1; i++)\n        \t{\n\t\t\tfor (int j = len-1; j > i; j--)\n\t\t\t{\n \t\t\t\tif (a[j] < a[j-1])\n\t\t\t\t\tswap(a, j-1, j);\n\t\t\t}\n        \t}\n\t}\n{% endcodeblock %}\n#### 分析\n冒泡排序在几乎排序的情况下只需$ O(N) $的时间复杂度，与插入排序具有很多相同的属性，但开销略高，表现在至少需要遍历数组2次，而插入接近1次。\n> 冒泡排序中若数据排序好了，仍会继续进行下一轮的比较，这是没有意义的，可以在每次迭代的过程中（代码中第4、5行间）插入一个标志变量flag，若在此轮迭代中发生交换操作，则置flag为1，若此轮迭代的flag为0则停止迭代。\n#### 演示图\n\n- 随机情况下\n{% asset_img bubble-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img bubble-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img bubble-sort_3.gif reversed %}\n\n### 选择排序\n最简单直观的排序，与冒泡排序有些类似，都是在每次迭代中把最小的数放在前面，但过程不同，它是通过对整体数组的选择。选择排序是**不稳定**的排序。\n#### 原理\n每次迭代中，遍历数组，找出最小的数，放在最前面，之后迭代除第一个数以外的所有元素，迭代到最后两个数，排序完成。\n\n- $ O(1) $的额外空间\n- $ O(N^2) $次比较\n- $ O(N) $次交换\n- 没有自适应性\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid select_sort(int a[], int len)\n\t{\n\t\tfor (int i = 0; i < len-1; i++)\n\t\t{\n\t\t\tint minIndex = i;\n\t\t\tfor (int j = i+1; j < len; j++)\n\t\t\t{\n\t\t\t\tif (a[j] < a[minIndex])\n\t\t\t\t\tminIndex = j;\n\t\t\t}\n\t\t\tif (minIndex != i)\n\t\t\t\tswap(a, i, minIndex);\n\t\t}\n\t}\n{% endcodeblock %}\n#### 分析\n选择排序相比于冒泡排序最大的区别在于它每次只有在确定了当前数组中最小数的情况下才会进行交换操作，大大减少了交换次数。\n#### 演示图\n\n- 随机情况下\n{% asset_img selection-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img selection-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img selection-sort_3.gif reversed %}\n\n### 插入排序\n插入排序不需要通过比较来达到排序目的的，它是通过找当前元素在排序数组中合适的位置，将它插入到那个合适的位置来完成任务的。插入排序是**稳定**的排序。\n#### 原理\n将数据分为有序部分和无序部分，初始化时有序部分为第一个元素，之后依次将无序部分的每个元素插入到有序部分中合适的位置，直到所有元素都在有序部分中。\n\n- $ O(1) $的额外空间\n- $ O(N^2) $次比较\n- $ O(N^2) $次交换\n- 自适应性\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid insert_sort(int a[], int len)\n\t{\n\t    for (int i = 1; i < len; i ++)\n\t    {\n\t        int j = i - 1;\n\t        int k = a[i];\n\t        while (j > -1 && k < a[j] )\n\t        {\n\t            a[j+1] = a[j];\n\t            j--;\n\t        }\n\t        a[j+1] = k;\n\t    }\n\t}\n{% endcodeblock %}\n#### 分析\n插入排序在几乎排序的情况下只需$ O(N) $的时间复杂度，开销很低。每次进行插入的时候都保证前面的数已经有序。\n#### 演示图\n\n- 随机情况下\n{% asset_img insertion-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img insertion-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img insertion-sort_3.gif reversed %}\n\n### 快速排序\n快速排序是表现最好的排序算法，思想来自冒泡排序。快速排序是通过比较并交换小数和大数，之后小数就会浮在上面，而大数会落在下面。快速排序在初始时要设定一个基准数，同时快速排序也是**不稳定**的。\n#### 原理\n首先从序列中设定一个基准数，将小于它的数放在它的左边，大于它的数放在右边。之后对左右两边的序列重复进行上述操作，直到各区间只有一个元素。\n\n- $ O(\\log(N)) $的额外空间\n- $ O(N^2) $的时间复杂度\n- 一般是$ O(N*\\log(N)) $的时间复杂度\n- 没有自适应性\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid quick_sort(int a[], int left, int right)\n\t{\n\t\tif (left < right)\n\t\t{\n\t\t\tint i = left, j = right, target = a[left];\n\t\t\twhile (i < j)\n\t\t\t{\n\t\t\t\twhile (i < j && a[j] > target)\n\t\t\t\t\tj--;\n\t\t\t\tif (i < j)\n\t\t\t\t\ta[i++] = a[j];\n\t\t\t\twhile (i < j && a[i] < target)\n\t\t\t\t\ti++;\n\t\t\t\tif (i < j)\n\t\t\t\t\ta[j] = a[i];\n\t\t\t}\n\t\t\ta[i] = target;\n\t\t\tquick_sort(a, left, i-1);\n\t\t\tquick_sort(a, i+1, right);\n\t\t}\n\t}\n{% endcodeblock %}\n#### 分析\n快速排序的主要思想：冒泡+二分+递归分治。\n#### 演示图\n\n- 随机情况下\n{% asset_img quick-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img quick-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img quick-sort_3.gif reversed %}\n\n### 归并排序\n归并排序是**稳定**的排序算法，它是分治法的一个典型应用。首先归并排序将序列进行递归二分，之后将每个排好序的区间进行归并操作完成排序任务。\n#### 原理\n将序列进行二分操作，直到每个区间只有一个元素时停止，这时可以认为每个区间都是有序的。之后进行归并操作，合并相邻两个区间，直到所有元素排好序为止。\n\n- $ \\Theta(N) $的额外空间\n- $ \\Theta(\\log(N)) $的额外空间（使用链表）\n- $ \\Theta(N*\\log(N)) $的时间复杂度\n- $ O(N) $的空间复杂度\n- 没有自适应性\n- 不需要随机访问数据\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid merge(int arr[], int temp_arr[], int start_index, int mid_index, int end_index)\n\t{\n\t    int i = start_index, j = mid_index + 1;\n\t    int k = 0;\n\t    while (i < mid_index+1 && j < end_index+1)\n\t    {\n\t        if (arr[i] > arr[j])\n\t            temp_arr[k++] = arr[j++];\n\t        else\n\t            temp_arr[k++] = arr[i++];\n\t    }\n\t    while (i < mid_index+1)\n\t    {\n\t        temp_arr[k++] = arr[i++];\n\t    }\n\t    while (j < end_index+1)\n\t        temp_arr[k++] = arr[j++];\n\t\n\t    for (i = 0, j = start_index; j < end_index+1; i++, j++)\n\t        arr[j] = temp_arr[i];\n\t}\n\t\n\tvoid merge_sort(int a[], int temp_a[], int start_index, int end_index)\n\t{\n\t    if (start_index < end_index)\n\t    {\n\t        int mid_index = (start_index + end_index) / 2;\n\t        merge_sort(a, temp_a, start_index, mid_index);\n\t        merge_sort(a, temp_a, mid_index+1, end_index);\n\t        merge(a, temp_a, start_index, mid_index, end_index);\n\t    }\n\t}\n{% endcodeblock %}\n#### 分析\n归并排序的主要思想就是先递归分解序列，再合并序列。合并的过程时主要过程，要逐次比较每个位置，建立一个临时数组，谁小就先放入临时数组中，同时指针往后移一个。\n#### 演示图\n\n- 随机情况下\n{% asset_img merge-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img merge-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img merge-sort_3.gif reversed %}\n\n### 堆排序\n堆排序在**Top k**问题中使用频繁，采用二叉堆的数据结构来实现，二叉堆是一个近似的完全二叉树。堆排序是**不稳定**的排序算法。\n\n> 二叉堆具有一些性质：\n> \n> 1. 父节点的*key*大于等于任何一个子节点*的key*\n> 2. 每个节点的左右子树都是一个二叉堆\n> \n#### 原理\n对二叉堆数组通过移除根节点进行有序化。首先将heap[0]与heap[N-1]交换，对heap[0...N-2]做最大堆调整。之后将heap[0]与heap[N-2]交换，对heap[0...N-3]做最大堆调整，以此类推，直到heap[0]与heap[1]交换。由于每次都是将最大数并入到后面的有序区间内，所以整个数组变得有序。\n\n- $ O(1) $的额外空间\n- $ O(N*\\log(N)) $的时间复杂度\n- 没有自适应性\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid heap_maxAdjust(int a[], int i, int len)\n\t{\n\t\tint child;\n\t\tint temp;\t\n\t\tfor (; 2*i+1 < len; i = child)\n\t\t{\n\t        \tchild = 2 * i + 1;\n\t        \tif (child < len-1 && a[child+1] > a[child])\n\t\t\t\tchild++;\n\n\t        \tif (a[i] < a[child])\n\t\t\t\tswap(a, i, child);\n\t        \telse\n\t            \t\tbreak;\n\t\t}\n\t}\n\t\n\tvoid heap_sort(int a[], int len)\n\t{\n\t\tint i;\n\t\tfor (int i = len/2-1; i >= 0; i--)\n\t\t\theap_maxAdjust(a, i, len);\n\t\n\t\tfor (i = len-1; i > 0; i--)\n\t\t{\n\t\t\tswap(a, 0, i);\n\t\t\theap_maxAdjust(arr, 0, i);\n\t\t}\n\t}\n{% endcodeblock %}\n#### 分析\n当对二叉堆进行了最大堆调整后，就可以直接找出最大的几个数，也就解决了**Top k**的问题。\n#### 演示图\n\n- 随机情况下\n{% asset_img heap-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img heap-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img heap-sort_3.gif reversed %}\n\n### 希尔排序\n希尔排序，也称递减增量排序，思想是分组插入排序，它是**不稳定**的排序算法。\n希尔排序是插入排序的一种高效率的实现。\n#### 原理\n将数组列在一个矩阵表中，对矩阵表中每一列的元素进行插入排序，行数代表步长，步长随着递归而减小，直到只有一列。\n\n- $ O(1) $的额外空间\n- $ O(N^\\frac{3}{2}) $的时间复杂度\n- 自适应性\n\n#### 代码\n{% codeblock lang:cpp %}\n\tvoid shell_insert(int a[], int len, int d) \n\t{\n\t\tfor(int i = d; i < len; i++) \n\t\t{\n\t\t\tint j = i - d;\n\t\t\tint temp = a[i]; \n\t\t\twhile (j >= 0 && arr[j] > temp) \n\t\t\t{\n\t\t\t    a[j+d] = a[j]; \n\t\t\t    j -= d;\n\t        \t}\n\t        \tif (j != i - d)\n\t            \t\ta[j+d] = temp;\n\t    \t}\n\t}\n\t\n\tvoid shell_sort(int a[], int len) \n\t{\n\t\tint d = len / 2;\n\t\twhile(d > 0) \n\t\t{\n\t\t\tshell_insert(a, d, len);\n\t        \td /= 2;\n\t    \t}\n\t}\n{% endcodeblock %}\n#### 分析\n代码中的 d 为步长，从数组长度的一半开始，每次减半，直到为0。步长的选择直接决定了希尔排序的复杂度。希尔排序在接近排序的情况下只需$ O(N*\\log(N)) $的时间复杂度。\n#### 演示图\n\n- 随机情况下\n{% asset_img shell-sort_1.gif random %}\n- 接近排序的情况下\n{% asset_img shell-sort_2.gif nearly sorted %}\n- 最差情况下\n{% asset_img shell-sort_3.gif reversed %}\n\n\n### 参考文献\n[https://www.toptal.com/developers/sorting-algorithms](https://www.toptal.com/developers/sorting-algorithms)\n\n[https://www.jianshu.com/p/f5baf7f27a7e](https://www.jianshu.com/p/f5baf7f27a7e)\n\n[http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/](http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/)\n\n\n","tags":["Method Summary"]},{"title":"Learning a Similarity Metric Discriminatively, with Application to Face Verification","url":"/2018/10/07/Learning-a-Similarity-Metric-Discriminatively-with-Application-to-Face-Verification/","content":"论文链接：[Chopra S, Hadsell R, LeCun Y. Learning a similarity metric discriminatively, with application to face verification[C]//Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. IEEE, 2005, 1: 539-546.](https://ieeexplore.ieee.org/abstract/document/1467314)\n\n### 主要内容\n这是一篇介绍**Siamese**网络的论文，提起Siamese网络，一般都会引用这篇文章和《Hamming Distance Metric Learning》。本文中，作者主要提出了一种**方法**是：如何从数据中寻找一种判断相似性的函数，即学习一种相似度度量的方法。方法使用的**场景**是：类别数量很多，在训练中并不知道类别，而且每种类别的训练样本数量很少。解决的**想法**是：学习一种将输入空间映射到目标空间的函数，使得目标空间中的L1范数近似于输入空间的语义距离。网络性能的**评价**是：错误接受的百分比和错误拒绝的百分比。学习的**过程**是：最小化一个有判别能力的损失函数，使相同类别物体的度量小，不同类别物体的度量大。总体思想是一个Metric Learning，即通过距离决定样本之间的关系，距离公式如下：\n\n$$ E_{w}(X_{1},X_{2}) = \\mid\\mid G_{w}(X_{1}) - G_{w}(X_{2}) \\mid\\mid $$\n\n其中参数为$ \\omega $，$X_{1}$和$X_{2}$是一对比较样本。\n\n### 网络结构\n\n<center>{% asset_img 1.PNG 300 300 Siamese网络结构图 %}</center>\n上图中参数w的两边是完全相同的网络结构，文中使用卷积网络，并共享相同的权值w，输入为一对图像(Y,X1,X2)，其中Y为标签，0为相似，1为不相似。针对不同的输入，分别输出低维空间的结果为$G_{w}(X_{1})$和$G_{w}(X_{2})$且由输入经过网络映射所得到，最终将这两个输出结果使用能量函数$E_{w}$进行比较。\n\n网络的损失函数，即Siamese网络中的Contrastive Loss为：\n\n$$\\Gamma(w) = \\sum_{i=1}^p L(w,(Y,X_{1},X_{2})^i)$$\n\n$$L(w,(Y,X_{1},X_{2})^i) = (1-Y)L_{G}(E_{w}(X_{1},X_{2})^i) + YL_{I}(E_{w}(X_{1},X_{2})^i)$$\n\n其中p为训练样本数量，$L_{G}$只计算正样本组合的损失，$L_{I}$只计算负样本组合的损失。通过这样分开的设计，可以使当要最小化损失函数时，减少正样本对的能量，增加负样本对的能量，能量也可以理解为距离，距离越小说明两个样本越相似。简单实现的话，只要将正样本组合损失函数设计为单调增加，将负样本组合损失函数设计为单调减少，但有一个前提是不同类别的图像对的距离肯定比相同类别的图像对的距离小。即得到了下列条件的条件一。\n\n论文中给出了三个条件和一个定理：\n\n<center>{% asset_img 2.PNG 500 60 Condition 1 %}</center>\n<center>{% asset_img 3.PNG 500 60 Condition 2 %}</center>\n<center>{% asset_img 4.PNG 500 80 Condition 3 %}</center>\n<center>{% asset_img 5.PNG 500 120 Theorem 1 %}</center>\n之后为了满足这些条件，论文中使用$H(E_{w}^G,E_{w}^I) = L_{G}(E_{w}^G) + L_{I}(E_{w}^I)$作为总体的损失函数，并用下图说明了收敛性：\n\n<center>{% asset_img 6.PNG 300 250 收敛性 %}</center>\n之后给出一个精确的对单个样本的损失函数，即对$ L_G $和$ L_I $的定义。此网络最重要的部分就是对这两个单个损失函数的定义，本文中只是给出了一个最初的设想，现在已经不常用了。\n\n$$L(w,Y,X_{1},X_{2}) = (1-Y)L_{G}(E_{w}) + YL_{I}(E_{w}) = (1-Y)\\frac{2}{Q}(E_{w})^2+(Y)2Qe^(-\\frac{2.77}{Q}E_{w})$$\n\n其中$G_{w}$，$E_{w}$是有界的，Q为常数，是$E_{w}$的上界，使用获得的损失值用梯度反转去更新共享的权值w。\n\n文中卷积网络的设计参数如下，基础结构按以下顺序。\n\n- $ C_1 $特征图个数为15，大小为$ 50\\times40 $，卷积核大小为$ 7\\times7 $，训练参数个数为750。\n- $ S_2 $特征图个数为15，大小为$ 25\\times20 $，感受野大小为$ 2\\times2 $，训练参数个数为30。\n- $ C_3 $特征图个数为45，大小为$ 20\\times15 $，卷积核大小为$ 6\\times6 $，训练参数个数为7128。其中部分连接到了$ S_2 $。\n- $ S_4 $特征图个数为45，大小为$ 5\\times5 $，感受野大小为$ 4\\times3 $，训练参数个数为100。\n- $ C_5 $特征图个数为250，大小为$ 1\\times1 $，卷积核大小为$ 5\\times5 $，训练参数个数为312750。全连接到 $ S_4 $。 \n- $ F_6 $单元大小为50，训练参数个数为12550。\n\n### 总结\n本文主要提出了一种具有判别能力的通过学习复杂的相似度度量的方法，非常适合于那些类别特别多，但训练过程中没有类别信息的任务，同时提出了一种损失函数可以达到上述的效果。本文提出的Siamese网络用于判别两个物体是否相似的任务上具有很好的效果，如**目标跟踪**任务。\n","tags":["Paper Review"]},{"title":"Deep Visual Tracking: Review and Experimental comparison","url":"/2018/09/14/Deep-Visual-Tracking-Review-and-Experimental-comparison/","content":"论文链接：[Li P, Wang D, Wang L, et al. Deep visual tracking: Review and experimental comparison[J]. Pattern Recognition, 2018, 76: 323-338.](https://ac.els-cdn.com/S0031320317304612/1-s2.0-S0031320317304612-main.pdf?_tid=54c136ff-a555-4feb-8bf1-5a7433919dfe&acdnat=1536931602_6895ff75c237f8520037a3b44a52a622)\n\n### 主要内容\n\n卢教授的一篇文章，大连理工大学的卢湖川教授也是跟踪领域中的一位厉害人物，曾经在ICCV发表的FCNT产生了很大的反响。这是一篇有关深度网络跟踪算法的综述论文，主要从**点评**和**实验比较**两个方面来说明。基于深度网络的跟踪算法主要依据网络的**结构**、**功能**、**训练**来分为三类，并在**OTB-100**、**TC-128**、**VOT-2015**三个数据集上比较性能。论文中总结出一些结论：\n- 使用卷积神经网络(CNN)确实能有效提升跟踪性能\n\n- 使用深度网络做前景和背景的二分类会有较好的性能，而用作模板匹配会有较高的效率\n\n- 深度网络所提取的特征相较于人工特征会有更好的性能\n\n- 不同的卷积层所提取的特征拥有着不同的特性，若对其有效组合会得到更鲁棒的跟踪算法\n\n- 端到端的网络模式相较于仅用来提取特征的模式性能更好\n\n- 最适宜的预训练方法是在视频数据集上进行，在跟踪阶段进行微调\n\n\n这篇文章主要注重这几个问题：\n\n1. 当前这些基于深度网络的跟踪算法有什么联系和区别？\n2. 为什么深度网络适合目标跟踪？\n3. 如何让深度网络对目标跟踪产生更好的影响？未来发展此领域的方向是什么？\n\n\n\n这篇文章在实验比较内容中一共对比了16种基于深度网络的跟踪算法和6种baseline方法。\n\n\n\n### 目标跟踪简介\n\n目标跟踪研究的内容就是在实际场景中使用算法跟踪从第一帧就标定好的目标。宽泛地讲，目标跟踪主要包含两种主要的元素：1. 描述物体当前状态并预测物体未来状态的运动模型，例如卡尔曼滤波器和粒子滤波器；2. 描述目标外观信息和确定预测目标的观察模型。一些研究者表明观察模型比运动模型更加重要。\n\n从观察模型的角度来说，跟踪算法经常被分为生成式方法和判别式方法。生成式方法聚焦于找寻最相似于目标的区域位置；而判别式方法将跟踪问题考虑为一个分类问题，主要聚焦于把目标前景和背景分开。\n\n\n\n<center>{% asset_img 1_1.png 600 600 论文中的类型简称 %}</center>\n\n\n\n### 网络结构\n\n#### 使用CNN模型\n\n**使用CNN模型去判别前景和背景(CNN-C)**\n在VGGNet中，卷积层中最后一层的输出往往包含语义信息和表征信息，使其对于图像的外观变化非常鲁棒，但空间分辨率很低，无法定位到目标的准确位置。相反，前面的卷积层就可以很精准的定位到目标位置，但却不适用于外观变化。那么把不同的层和相关滤波器结合就是一种很好的方法，结构如图。\n<center>{% asset_img 1_2.png 500 250 CNN-C结构模型 %}</center>\n\n\n\n**使用CNN模型去匹配目标模板(CNN-M)**\n\n此类结构主要使用CNN模型去学习一个有效的**匹配**函数，从候选目标中匹配到准确的目标模板来实现跟踪任务，如Siamese网络，从候选区域中匹配目标，得到特征匹配图，结构如图。\n<center>{% asset_img 1_3.png 500 250 CNN-M结构模型 %}</center>\n\n\n\n#### 使用RNN模型\n\n利用空间结构性和时间有序性，RNN网络的特征能够较好的攻克**遮挡**难关，且RNN和CNN相结合会更加提升特征的鲁棒性，利用LSTM的时间关联性能够在跟踪过程中形成长时间记忆。\n\n\n\n#### 使用其他网络模型\n\n主要是自编码器的应用，使用浅层特征和深层特征相结合的方法，适用于外观变化的情况。具体内容请查看论文中的3.1.3节。\n\n\n\n### 网络功能\n\n#### 仅使用深度网络来提取特征的跟踪算法(FEN) ##\n\n1. 从深度网络中提取某一层的特征(FEN-SL)\n2. 从深度网络中提取多层的特征(FEN-ML)\n\n\n\n#### 端到端的深度网络跟踪算法(EEN)\n\n1. 利用粒子滤波器或者滑动窗口策略产生一系列的候选目标，之后产生每个候选目标的得分数从而确定目标位置(EEN-S)\n2. 使用深度网络去生成一个置信图(confidence map)、概率图(probablyility map)、响应图(response map)、热度图(heat map)，之后使用其他的方法去定位目标(EEN-M)\n3. 使用深度网络直接产生bounding box位置(EEN-B)\n\n\n\n### 网络训练\n\n1. 不用预训练+在线学习(NP-OL)\n2. 图像预训练+非在线学习(主要使用VGGNet)(IP-NOL)\n3. 图像预训练+在线学习(IP-OL)\n4. 视频预训练+非在线学习：卷积层目的是提取深层特征，全连接层目的是学习如何区分目标模板和候选样本，这是一个复杂的特征比较学习过程。(VP-NOL)\n5. 视频预训练+在线学习(MDNet)：如图所示。(VP-OL)\n<center>{% asset_img 1_4.png 600 300 MDNet网络模型 %}</center>\n\n此外，深度增强学习（DRL）也在目标跟踪领域中扮演着重要的角色，它很适合缺少训练标签或者之后才能活着标签的任务。\n\n\n\n### 分析部分\n\n1. 分析网络结构：CNN模型表现出很好的性能，但却无法对连续的帧进行建模，导致它无法有效利用跟踪任务的时间信息。而RNN却可以描述时间或空间的关系，在这方面的研究还很欠缺。\n2. 分析网络功能：端到端的跟踪算法比仅用深度网络提特征的算法好，表明深度网络在分类和匹配的功能上比传统方法更好。\n3. 分析网络训练：离线预训练可以减少额外的计算量和空间损耗，而在线fine-tune可以时刻改变模板和性能。使用图像进行预训练可以提升性能，而使用视频进行预训练更符合跟踪任务的特性，可能会达到更好的效果。\n4. 分析跟踪速度：跟踪任务的图像分辨率普遍比分类任务低，如果采用深层网络可能会丢失很多信息。在模板更新方面，每隔几帧更新模板的方法和使用一个通道网络去进行模板匹配而不是在线更新分类器的方法，两者都取得了很好的效果。\n\n<center>{% asset_img 1_5.png 800 250 OTB-100的实验结果(OPE) %}</center>\n\n<center>{% asset_img 1_6.png 800 250 TC-128的实验结果(OPE) %}</center>\n\n<center>{% asset_img 1_7.png 600 350 跟踪算法的速度比较 %}</center>\n\n\n\n### 欠缺的研究方向\n\n1. 深度特征包含很多冗余性，限制了速度和性能的提升，降低深度特征的冗余度，提升跟踪速率。\n2. 很多方法都是使用VGG网络，发展更多有效的网络很急迫。\n3. 由于跟踪任务缺少训练数据，那么无监督或弱监督学习就比较适合。增强学习和生成对抗网络也可以用来产生更多的训练样本来提升跟踪性能。\n4. 模型的转移能力在跟踪任务中很重要，one-shot learning也是一个新的方向。\n5. 提升算法的有效性和解决训练样本的缺失性会是一个新的方向。\n","tags":["Paper Review"]}]